"""
æ‹¡å¼µã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
1. ãƒ¬ãƒ¼ã‚¹æ¡ä»¶åˆ¥ (èŠ vs ãƒ€ãƒ¼ãƒˆ, è·é›¢, ã‚¯ãƒ©ã‚¹)
2. ç«¶é¦¬å ´åˆ¥
4. äººæ°—é †ä½åˆ¥
5. AIã‚¹ã‚³ã‚¢å·®åˆ¥ (Top1 - Top2)
"""
import os
import sys
import pandas as pd
import numpy as np
from itertools import combinations, permutations, product
from collections import defaultdict
import logging
from scipy.special import softmax
from sqlalchemy import create_engine, text

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_db_engine():
    user = os.environ.get('POSTGRES_USER', 'postgres')
    password = os.environ.get('POSTGRES_PASSWORD', 'postgres')
    host = os.environ.get('POSTGRES_HOST', 'db')
    port = os.environ.get('POSTGRES_PORT', '5432')
    dbname = os.environ.get('POSTGRES_DB', 'pckeiba')
    return create_engine(f"postgresql://{user}:{password}@{host}:{port}/{dbname}")

def load_predictions_from_db(years=[2024, 2025]):
    data_path = 'data/processed/preprocessed_data.parquet'
    df = pd.read_parquet(data_path)
    df = df[df['year'].isin(years)].copy()
    logger.info(f"Loaded {len(df)} rows for years {years}")
    return df

def load_model_and_predict(df, model_name='ensemble', version='v4_2025'):
    sys.path.append('src')
    from model.ensemble import EnsembleModel
    
    model = EnsembleModel()
    model.load_model(f'models/ensemble_{version}.pkl')
    
    import pickle
    with open('data/processed/lgbm_datasets.pkl', 'rb') as f:
        datasets = pickle.load(f)
    feature_cols = datasets['train']['X'].columns.tolist()
    
    for c in feature_cols:
        if c not in df.columns:
            df[c] = 0
    
    X = df[feature_cols]
    scores = model.predict(X)
    df['score'] = scores
    
    return df

def load_payouts(years=[2024, 2025]):
    engine = get_db_engine()
    years_str = ",".join([f"'{y}'" for y in years])
    query = text(f"SELECT * FROM jvd_hr WHERE kaisai_nen IN ({years_str})")
    df = pd.read_sql(query, engine)
    
    df['race_id'] = (
        df['kaisai_nen'].astype(str) +
        df['keibajo_code'].astype(str) +
        df['kaisai_kai'].astype(str) +
        df['kaisai_nichime'].astype(str) +
        df['race_bango'].astype(str)
    )
    return df

def build_payout_map(pay_df):
    payout_map = defaultdict(lambda: {'tansho': {}, 'umaren': {}, 'sanrenpuku': {}, 'sanrentan': {}})
    
    for _, row in pay_df.iterrows():
        rid = row['race_id']
        
        for prefix, max_count in [('haraimodoshi_tansho', 3), ('haraimodoshi_umaren', 3), 
                                   ('haraimodoshi_sanrenpuku', 3), ('haraimodoshi_sanrentan', 6)]:
            bet_type = prefix.split('_')[1]
            for i in range(1, max_count + 1):
                col_a = f'{prefix}_{i}a'
                col_b = f'{prefix}_{i}b'
                if col_a in row and row[col_a] and str(row[col_a]).strip():
                    try:
                        key = str(row[col_a]).strip()
                        val = int(float(str(row[col_b]).strip()))
                        payout_map[rid][bet_type][key] = val
                    except:
                        pass
    
    return dict(payout_map)

def preprocess_data(df):
    df = df.copy()
    df['score'] = pd.to_numeric(df['score'], errors='coerce')
    df['rank'] = pd.to_numeric(df['rank'], errors='coerce')
    df['odds'] = pd.to_numeric(df['odds'], errors='coerce')
    df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')
    df['distance'] = pd.to_numeric(df['distance'], errors='coerce')
    
    df['pred_rank'] = df.groupby('race_id')['score'].rank(method='first', ascending=False)
    df['prob'] = df.groupby('race_id')['score'].transform(lambda x: softmax(x))
    df['ev'] = df['prob'] * df['odds'].fillna(0)
    
    # ã‚¹ã‚³ã‚¢å·® (Top1 - Top2)
    df['score_max'] = df.groupby('race_id')['score'].transform('max')
    df['score_second'] = df.groupby('race_id')['score'].transform(lambda x: x.nlargest(2).iloc[-1] if len(x) >= 2 else x.max())
    df['score_gap'] = df['score_max'] - df['score_second']
    
    return df

def get_race_features(df):
    """ãƒ¬ãƒ¼ã‚¹ã”ã¨ã®ç‰¹å¾´é‡ã‚’å–å¾—"""
    race_features = {}
    
    for rid, grp in df.groupby('race_id'):
        sorted_g = grp.sort_values('score', ascending=False)
        top1 = sorted_g.iloc[0] if len(sorted_g) > 0 else None
        top2 = sorted_g.iloc[1] if len(sorted_g) > 1 else None
        
        if top1 is None:
            continue
        
        # é¦¬å ´ (èŠ/ãƒ€ãƒ¼ãƒˆ)
        surface = top1.get('surface', '')
        if pd.isna(surface): surface = ''
        
        # è·é›¢ã‚«ãƒ†ã‚´ãƒª
        dist = top1.get('distance', 0)
        if pd.isna(dist): dist = 0
        if dist <= 1400:
            dist_cat = 'sprint'
        elif dist <= 2000:
            dist_cat = 'mile'
        else:
            dist_cat = 'long'
        
        # ç«¶é¦¬å ´
        venue = str(rid)[4:6] if len(str(rid)) >= 6 else ''
        
        # Top1ã®äººæ°—
        pop = top1.get('popularity', 99)
        if pd.isna(pop): pop = 99
        
        # ã‚¹ã‚³ã‚¢å·®
        score_gap = top1.get('score_gap', 0)
        if pd.isna(score_gap): score_gap = 0
        
        race_features[rid] = {
            'surface': surface,
            'dist_cat': dist_cat,
            'venue': venue,
            'top1_popularity': int(pop),
            'score_gap': score_gap,
            'top1_odds': top1['odds'] if not pd.isna(top1['odds']) else 0,
            'top1_ev': top1['ev'],
            'top1_rank': top1['rank'],
            'top1_horse': int(top1['horse_number']),
            'horses': sorted_g['horse_number'].astype(int).tolist()
        }
    
    return race_features

def run_segment_analysis(race_features, payout_map, segment_name, segment_func):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ROIåˆ†æ"""
    segments = defaultdict(lambda: {'races': 0, 'cost': 0, 'return': 0, 'hits': 0})
    
    for rid, rf in race_features.items():
        if rid not in payout_map:
            continue
        
        seg = segment_func(rf)
        if seg is None:
            continue
        
        # å˜å‹ã§ãƒ†ã‚¹ãƒˆ
        odds = rf['top1_odds']
        actual_rank = rf['top1_rank']
        
        cost = 100
        ret = odds * 100 if actual_rank == 1 else 0
        
        segments[seg]['races'] += 1
        segments[seg]['cost'] += cost
        segments[seg]['return'] += ret
        segments[seg]['hits'] += 1 if actual_rank == 1 else 0
    
    return segments

def print_segment_results(title, segments, min_races=30):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµæœè¡¨ç¤º"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š {title}")
    print(f"{'='*70}")
    
    results = []
    for seg, s in segments.items():
        if s['races'] >= min_races:
            roi = s['return'] / s['cost'] * 100 if s['cost'] > 0 else 0
            hit_rate = s['hits'] / s['races'] * 100 if s['races'] > 0 else 0
            results.append({
                'segment': seg,
                'races': s['races'],
                'roi': roi,
                'hit_rate': hit_rate,
                'profit': s['return'] - s['cost']
            })
    
    results = sorted(results, key=lambda x: x['roi'], reverse=True)
    
    print(f"{'ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ':<20} | {'Races':>6} | {'ROI':>8} | {'çš„ä¸­ç‡':>7} | {'åˆ©ç›Š':>10}")
    print("-" * 70)
    
    for r in results:
        profit_str = f"Â¥{r['profit']:+,.0f}"
        print(f"{str(r['segment']):<20} | {r['races']:>6} | {r['roi']:>7.1f}% | {r['hit_rate']:>6.1f}% | {profit_str:>10}")
    
    if results:
        best = results[0]
        print(f"\nğŸ† ãƒ™ã‚¹ãƒˆ: {best['segment']} (ROI {best['roi']:.1f}%, {best['races']}ãƒ¬ãƒ¼ã‚¹)")
    
    return results

def main():
    print("\n" + "#"*80)
    print("# ğŸ“Š æ‹¡å¼µã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ (2024+2025å¹´)")
    print("# åˆ‡ã‚Šå£: é¦¬å ´/è·é›¢/ç«¶é¦¬å ´/äººæ°—/ã‚¹ã‚³ã‚¢å·®")
    print("#"*80)
    
    years = [2024, 2025]
    
    df = load_predictions_from_db(years)
    df = load_model_and_predict(df, 'ensemble', 'v4_2025')
    df = preprocess_data(df)
    
    pay_df = load_payouts(years)
    payout_map = build_payout_map(pay_df)
    logger.info(f"Built payout map for {len(payout_map)} races")
    
    race_features = get_race_features(df)
    logger.info(f"Extracted features for {len(race_features)} races")
    
    all_results = {}
    
    # 1. é¦¬å ´åˆ¥ (èŠ vs ãƒ€ãƒ¼ãƒˆ)
    segments = run_segment_analysis(
        race_features, payout_map, 
        "é¦¬å ´åˆ¥",
        lambda rf: rf['surface'] if rf['surface'] in ['èŠ', 'ãƒ€ãƒ¼ãƒˆ', 'Turf', 'Dirt'] else None
    )
    all_results['surface'] = print_segment_results("é¦¬å ´åˆ¥ (å˜å‹Top1)", segments)
    
    # 2. è·é›¢åˆ¥
    segments = run_segment_analysis(
        race_features, payout_map,
        "è·é›¢åˆ¥",
        lambda rf: rf['dist_cat']
    )
    all_results['distance'] = print_segment_results("è·é›¢åˆ¥ (å˜å‹Top1)", segments)
    
    # 3. ç«¶é¦¬å ´åˆ¥
    venue_names = {
        '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ',
        '05': 'æ±äº¬', '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½',
        '09': 'é˜ªç¥', '10': 'å°å€‰'
    }
    segments = run_segment_analysis(
        race_features, payout_map,
        "ç«¶é¦¬å ´åˆ¥",
        lambda rf: venue_names.get(rf['venue'], rf['venue'])
    )
    all_results['venue'] = print_segment_results("ç«¶é¦¬å ´åˆ¥ (å˜å‹Top1)", segments)
    
    # 4. Top1äººæ°—åˆ¥
    def pop_category(rf):
        pop = rf['top1_popularity']
        if pop == 1: return '1ç•ªäººæ°—'
        elif pop <= 3: return '2-3ç•ªäººæ°—'
        elif pop <= 6: return '4-6ç•ªäººæ°—'
        elif pop <= 10: return '7-10ç•ªäººæ°—'
        else: return '11ç•ªäººæ°—ä»¥ä¸‹'
    
    segments = run_segment_analysis(
        race_features, payout_map,
        "Top1äººæ°—åˆ¥",
        pop_category
    )
    all_results['popularity'] = print_segment_results("Top1äººæ°—åˆ¥ (å˜å‹Top1)", segments)
    
    # 5. ã‚¹ã‚³ã‚¢å·®åˆ¥
    def score_gap_category(rf):
        gap = rf['score_gap']
        if gap >= 0.5: return 'Gapâ‰¥0.5 (å¤§å·®)'
        elif gap >= 0.3: return 'Gap 0.3-0.5'
        elif gap >= 0.1: return 'Gap 0.1-0.3'
        else: return 'Gap<0.1 (åƒ…å·®)'
    
    segments = run_segment_analysis(
        race_features, payout_map,
        "ã‚¹ã‚³ã‚¢å·®åˆ¥",
        score_gap_category
    )
    all_results['score_gap'] = print_segment_results("ã‚¹ã‚³ã‚¢å·®åˆ¥ (å˜å‹Top1)", segments)
    
    # è¤‡åˆæ¡ä»¶ãƒ†ã‚¹ãƒˆ (æœ€ã‚‚æœ‰æœ›ãªçµ„ã¿åˆã‚ã›)
    print("\n" + "="*70)
    print("ğŸ“Š è¤‡åˆæ¡ä»¶ãƒ†ã‚¹ãƒˆ (æœ‰æœ›ãªçµ„ã¿åˆã‚ã›)")
    print("="*70)
    
    combo_segments = defaultdict(lambda: {'races': 0, 'cost': 0, 'return': 0, 'hits': 0})
    
    for rid, rf in race_features.items():
        if rid not in payout_map:
            continue
        
        surface = rf['surface']
        gap_cat = score_gap_category(rf)
        pop = rf['top1_popularity']
        odds = rf['top1_odds']
        
        # è¤‡åˆã‚­ãƒ¼
        key = f"{surface}_{gap_cat}_Pop{pop if pop <= 3 else '4+'}"
        
        cost = 100
        ret = odds * 100 if rf['top1_rank'] == 1 else 0
        
        combo_segments[key]['races'] += 1
        combo_segments[key]['cost'] += cost
        combo_segments[key]['return'] += ret
        combo_segments[key]['hits'] += 1 if rf['top1_rank'] == 1 else 0
    
    all_results['combo'] = print_segment_results("è¤‡åˆæ¡ä»¶ (å˜å‹Top1)", combo_segments, min_races=20)
    
    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open('reports/extended_grid_search.txt', 'w', encoding='utf-8') as f:
        f.write("=== æ‹¡å¼µã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒçµæœ (2024+2025å¹´) ===\n\n")
        
        for category, results in all_results.items():
            f.write(f"\n--- {category} ---\n")
            if results:
                for r in results[:10]:
                    f.write(f"{r['segment']}: ROI {r['roi']:.1f}%, {r['races']}ãƒ¬ãƒ¼ã‚¹, Hit {r['hit_rate']:.1f}%\n")
    
    print("\nçµæœã‚’ reports/extended_grid_search.txt ã«ä¿å­˜ã—ã¾ã—ãŸ")
    print("\nâœ… æ‹¡å¼µã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå®Œäº†!")

if __name__ == "__main__":
    main()
