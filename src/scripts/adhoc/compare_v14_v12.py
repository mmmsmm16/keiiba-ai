"""
v14 ROIãƒ¢ãƒ‡ãƒ« vs v12 æ¯”è¼ƒè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- v14: PyTorch ROIæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«
- v12: LightGBM+CatBoost+TabNet Ensemble
"""
import os
import sys
import pandas as pd
import numpy as np
import pickle
import logging
from collections import defaultdict
from scipy.special import softmax
from sqlalchemy import create_engine, text

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ãƒ‘ã‚¹è¨­å®š
import os
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(script_dir, '../../..'))
sys.path.insert(0, project_root)

def get_db_engine():
    user = os.environ.get('POSTGRES_USER', 'postgres')
    password = os.environ.get('POSTGRES_PASSWORD', 'postgres')
    host = os.environ.get('POSTGRES_HOST', 'db')
    port = os.environ.get('POSTGRES_PORT', '5432')
    dbname = os.environ.get('POSTGRES_DB', 'pckeiba')
    return create_engine(f"postgresql://{user}:{password}@{host}:{port}/{dbname}")

def load_payouts(year):
    engine = get_db_engine()
    query = text(f"SELECT * FROM jvd_hr WHERE kaisai_nen = '{year}'")
    df = pd.read_sql(query, engine)
    
    df['race_id'] = (
        df['kaisai_nen'].astype(str) +
        df['keibajo_code'].astype(str) +
        df['kaisai_kai'].astype(str) +
        df['kaisai_nichime'].astype(str) +
        df['race_bango'].astype(str)
    )
    return df

def build_payout_map(pay_df):
    payout_map = defaultdict(lambda: {'tansho': {}})
    
    for _, row in pay_df.iterrows():
        rid = row['race_id']
        for i in range(1, 4):
            col_a = f'haraimodoshi_tansho_{i}a'
            col_b = f'haraimodoshi_tansho_{i}b'
            if col_a in row and row[col_a] and str(row[col_a]).strip():
                try:
                    key = str(row[col_a]).strip()
                    val = int(float(str(row[col_b]).strip()))
                    payout_map[rid]['tansho'][key] = val
                except:
                    pass
    return dict(payout_map)

def evaluate_model_predictions(df, model_name, payout_map=None):
    """ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚’è©•ä¾¡"""
    results = {
        'model': model_name,
        'races': 0,
        'hits': 0,
        'cost': 0,
        'return': 0
    }
    
    for race_id, grp in df.groupby('race_id'):
        if 'score' not in grp.columns or grp['score'].isnull().all():
            continue
        
        # Top1äºˆæ¸¬
        sorted_g = grp.sort_values('score', ascending=False)
        top1 = sorted_g.iloc[0]
        
        results['races'] += 1
        results['cost'] += 100
        
        # çš„ä¸­åˆ¤å®š
        rank = top1.get('rank', 99)
        if pd.isna(rank):
            rank = 99
        
        if rank == 1:
            results['hits'] += 1
            odds = top1.get('odds', 0)
            if pd.isna(odds):
                odds = 0
            results['return'] += odds * 100
    
    # æŒ‡æ¨™è¨ˆç®—
    if results['cost'] > 0:
        results['roi'] = results['return'] / results['cost'] * 100
        results['accuracy'] = results['hits'] / results['races'] * 100
    else:
        results['roi'] = 0
        results['accuracy'] = 0
    
    return results

def predict_with_v12(df, feature_cols):
    """v12ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"""
    from src.model.ensemble import EnsembleModel
    
    model = EnsembleModel()
    # CPUãƒ¢ãƒ¼ãƒ‰ã§ãƒ­ãƒ¼ãƒ‰ï¼ˆCUDAã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
    model.load_model('experiments/v12_tabnet_revival/models/ensemble.pkl', device_name='cpu')
    
    # æ¬ æã‚«ãƒ©ãƒ è£œå®Œ
    for c in feature_cols:
        if c not in df.columns:
            df[c] = 0
    
    X = df[feature_cols]
    scores = model.predict(X)
    df['score'] = scores
    
    return df

def predict_with_v14(df, feature_cols):
    """v14 ROIãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"""
    import torch
    from src.model.roi_model import ROIModel
    
    model = ROIModel()
    model.load('experiments/v14_roi/models/roi_model_best.pt')
    
    # æ•°å€¤å‹ã‚«ãƒ©ãƒ ã®ã¿ä½¿ç”¨
    numeric_df = df[feature_cols].select_dtypes(include=[np.number])
    actual_feature_cols = numeric_df.columns.tolist()
    
    # ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›æ¬¡å…ƒã«åˆã‚ã›ã‚‹
    if model.input_dim != len(actual_feature_cols):
        logger.warning(f"Feature mismatch: model expects {model.input_dim}, got {len(actual_feature_cols)}")
        # è¶³ã‚Šãªã„ã‚«ãƒ©ãƒ ã¯0åŸ‹ã‚
        diff = model.input_dim - len(actual_feature_cols)
        if diff > 0:
            for i in range(diff):
                actual_feature_cols.append(f'_dummy_{i}')
                df[f'_dummy_{i}'] = 0
    
    # ãƒ¬ãƒ¼ã‚¹å˜ä½ã§äºˆæ¸¬
    all_scores = []
    
    for race_id, grp in df.groupby('race_id'):
        grp = grp.sort_values('horse_number')
        
        # 3Då½¢å¼ã«å¤‰æ›
        X = grp[actual_feature_cols[:model.input_dim]].values.astype(np.float32)
        X = np.nan_to_num(X, nan=0.0)
        
        n_horses = len(grp)
        max_horses = 18
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        X_padded = np.zeros((1, max_horses, model.input_dim), dtype=np.float32)
        mask = np.zeros((1, max_horses), dtype=np.float32)
        
        n = min(n_horses, max_horses)
        X_padded[0, :n, :] = X[:n]
        mask[0, :n] = 1.0
        
        # äºˆæ¸¬
        scores = model.predict(X_padded, mask)
        
        # ã‚¹ã‚³ã‚¢ã‚’DataFrameã«æˆ»ã™
        race_scores = scores[0, :n]
        for i, (idx, row) in enumerate(grp[:n].iterrows()):
            all_scores.append({'idx': idx, 'score': race_scores[i]})
    
    # ã‚¹ã‚³ã‚¢ã‚’å…ƒã®DataFrameã«è¿½åŠ 
    score_df = pd.DataFrame(all_scores).set_index('idx')
    df['score'] = score_df['score']
    
    return df

def main():
    print("\n" + "="*80)
    print("ğŸ“Š v14 ROI Model vs v12 Ensemble æ¯”è¼ƒè©•ä¾¡")
    print("="*80)
    
    year = 2025
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\n1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    data_path = 'experiments/v14_roi/data/preprocessed_data.parquet'
    df = pd.read_parquet(data_path)
    df = df[df['year'] == year].copy()
    
    # JRAã®ã¿
    jra_codes = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']
    df['venue_code'] = df['race_id'].astype(str).str[4:6]
    df = df[df['venue_code'].isin(jra_codes)].copy()
    
    logger.info(f"Loaded {len(df)} rows for {year} (JRA only)")
    
    # æ•°å€¤å¤‰æ›
    df['rank'] = pd.to_numeric(df['rank'], errors='coerce')
    df['odds'] = pd.to_numeric(df['odds'], errors='coerce')
    df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')
    df['horse_number'] = pd.to_numeric(df['horse_number'], errors='coerce').fillna(1).astype(int)
    
    # æ‰•æˆ»ãƒ‡ãƒ¼ã‚¿
    print("2. æ‰•æˆ»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    pay_df = load_payouts(year)
    payout_map = build_payout_map(pay_df)
    logger.info(f"Loaded payouts for {len(payout_map)} races")
    
    # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ å–å¾—
    with open('experiments/v14_roi/data/lgbm_datasets.pkl', 'rb') as f:
        datasets = pickle.load(f)
    feature_cols = datasets['train']['X'].columns.tolist()
    
    results = []
    
    # v12è©•ä¾¡
    print("\n3. v12 Ensembleè©•ä¾¡...")
    try:
        df_v12 = df.copy()
        df_v12 = predict_with_v12(df_v12, feature_cols)
        v12_result = evaluate_model_predictions(df_v12, 'v12 Ensemble')
        results.append(v12_result)
        logger.info(f"v12: ROI {v12_result['roi']:.1f}%, Acc {v12_result['accuracy']:.1f}%")
    except Exception as e:
        logger.error(f"v12 evaluation failed: {e}")
    
    # v14è©•ä¾¡
    print("\n4. v14 ROI Modelè©•ä¾¡...")
    try:
        df_v14 = df.copy()
        df_v14 = predict_with_v14(df_v14, feature_cols)
        v14_result = evaluate_model_predictions(df_v14, 'v14 ROI')
        results.append(v14_result)
        logger.info(f"v14: ROI {v14_result['roi']:.1f}%, Acc {v14_result['accuracy']:.1f}%")
    except Exception as e:
        logger.error(f"v14 evaluation failed: {e}")
        import traceback
        traceback.print_exc()
    
    # çµæœè¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“Š è©•ä¾¡çµæœæ¯”è¼ƒ")
    print("="*80)
    print(f"{'ãƒ¢ãƒ‡ãƒ«':<20} | {'ROI':>8} | {'çš„ä¸­ç‡':>8} | {'ãƒ¬ãƒ¼ã‚¹æ•°':>8} | {'åˆ©ç›Š':>12}")
    print("-"*70)
    
    for r in results:
        profit = r['return'] - r['cost']
        print(f"{r['model']:<20} | {r['roi']:>7.1f}% | {r['accuracy']:>7.1f}% | {r['races']:>8} | {profit:>+12,.0f}å††")
    
    # å‹è€…
    if len(results) >= 2:
        best = max(results, key=lambda x: x['roi'])
        print(f"\nğŸ† å‹è€…: {best['model']} (ROI {best['roi']:.1f}%)")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    os.makedirs('reports', exist_ok=True)
    with open('reports/v14_vs_v12_comparison.txt', 'w', encoding='utf-8') as f:
        f.write("=== v14 ROI Model vs v12 Ensemble æ¯”è¼ƒ ===\n\n")
        for r in results:
            profit = r['return'] - r['cost']
            f.write(f"{r['model']}: ROI {r['roi']:.1f}%, Acc {r['accuracy']:.1f}%, {r['races']}ãƒ¬ãƒ¼ã‚¹, åˆ©ç›Š {profit:+,.0f}å††\n")
    
    print("\nçµæœã‚’ reports/v14_vs_v12_comparison.txt ã«ä¿å­˜ã—ã¾ã—ãŸ")
    print("\nâœ… æ¯”è¼ƒè©•ä¾¡å®Œäº†!")

if __name__ == "__main__":
    main()
