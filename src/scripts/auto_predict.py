import os
import sys
import json
import time
import requests
import argparse
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from scipy.stats import entropy
import pickle

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.model.ensemble import EnsembleModel
from src.inference.preprocessor import InferencePreprocessor
from src.inference.loader import InferenceDataLoader
from src.model.calibration import ProbabilityCalibrator

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(os.path.join(os.path.dirname(__file__), '../../logs/auto_predict.log'))
    ]
)
logger = logging.getLogger(__name__)


# .env æ‰‹å‹•èª­ã¿è¾¼ã¿
def load_env_manual():
    try:
        env_path = os.path.join(os.path.dirname(__file__), '../../.env')
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'): continue
                    if '=' in line:
                        key, val = line.split('=', 1)
                        os.environ[key.strip()] = val.strip()
    except Exception as e:
        logger.warning(f".env reading failed: {e}")

# å®šæ•°
STATE_FILE_PATH = os.path.join(os.path.dirname(__file__), '../../data/state/notified_races.json')

class NotificationManager:
    """Discordé€šçŸ¥ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url

    def _calculate_confidence(self, df: pd.DataFrame) -> tuple[str, str]:
        """ãƒã‚¶ãƒ¼ãƒ‰(æ³¢ä¹±åº¦)ã¨è‡ªä¿¡åº¦ã‚’åˆ¤å®š"""
        # å‹ç‡åˆ†å¸ƒã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
        probs = df['calibrated_prob'].values
        ent = entropy(probs)
        
        top_horse = df.sort_values('score', ascending=False).iloc[0]
        top_prob = top_horse['calibrated_prob']
        top_score = top_horse['score']
        
        # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        if top_prob >= 0.40 or top_score >= 1.5:
            return "S", "é‰„æ¿ (Ironclad)"
        elif top_prob >= 0.25 or top_score >= 0.8:
            return "A", "å®‰å®š (Stable)"
        elif ent > 2.0 or top_prob < 0.20:
             return "C", "æ³¢ä¹± (High Chaos)"
        else:
             return "B", "æ··æˆ¦ (Confusion)"

    def send_prediction(self, race_meta: Dict, df: pd.DataFrame):
        """
        äºˆæ¸¬çµæœã‚’Discordã«é€ä¿¡ã—ã¾ã™ã€‚
        Args:
            race_meta: ãƒ¬ãƒ¼ã‚¹æƒ…å ±
            df: äºˆæ¸¬çµæœDataFrame
        Returns:
            bool: é€ä¿¡æˆåŠŸãªã‚‰True
        """
        if not self.webhook_url:
            logger.warning("Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return False

        # ã‚¿ã‚¤ãƒˆãƒ«æ•´å½¢
        date_str = race_meta.get('date', '')
        
        # æ³¢ä¹±åº¦åˆ¤å®š
        chart_rank, chart_desc = self._calculate_confidence(df)
        
        title_str = f"ğŸ¯ [{date_str}] {race_meta['venue_name']}{race_meta['race_number']}R {race_meta['title']} ({race_meta['start_time']}) - [{chart_rank}] {chart_desc}"

        # äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ (å…¨é ­: ã‚¹ã‚³ã‚¢é † -> æœ€ã‚‚ç´”ç²‹ãªå¼·ã•è©•ä¾¡)
        top_picks = df.sort_values('score', ascending=False)
        
        description = "**ğŸ† æœ¬å‘½äºˆæ¸¬ (ã‚¹ã‚³ã‚¢é †)**\n"
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã€ãƒªã‚¹ãƒˆå½¢å¼ã§è¦‹ã‚„ã™ã
        marks = ["â—", "ã€‡", "â–²", "â–³", "â–³", "â–³"]
        
        for i, (_, row) in enumerate(top_picks.iterrows()):
            mark = marks[i] if i < len(marks) else "  "
            h_num = str(int(row['horse_number'])).zfill(2)
            h_name = row['horse_name']
            
            ev = f"{row['expected_value']:.2f}"
            prob = f"{row['calibrated_prob']*100:.0f}%"
            score = f"{row['score']:.2f}"
            
            # Simple list format with Score
            description += f"`{mark}` `{h_num}` **{h_name}** (å‹ç‡:{prob}, EV:{ev}, Sc:{score})\n"

        # æ¨å¥¨è²·ã„ç›® (Smart Value Logic)
        bet_strategy = self._generate_betting_strategy(df)
        
        # NetKeiba Link
        # IDå½¢å¼è£œæ­£: YYYY(4) + Venue(2) + Kai(2) + Nichi(2) + R(2) 
        # race_meta['race_id'] ã¯é€šå¸¸ã“ã®å½¢å¼ã€‚
        netkeiba_url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_meta['race_id']}"
        description += f"\nğŸ”— [NetKeiba]({netkeiba_url})\n"
        
        embed = {
            "title": title_str,
            "description": description + "\n" + bet_strategy,
            "color": 0xFF0000 if top_picks.iloc[0]['expected_value'] > 1.5 else (0x00FF00 if chart_rank in ['S', 'A'] else 0xFFA500), # S/Aãªã‚‰ç·‘ã€ãã‚Œä»¥å¤–ã¯ã‚ªãƒ¬ãƒ³ã‚¸ã€é«˜EVã¯èµ¤
            "footer": {
                "text": "Keiiba-AI Prediction System"
            }
        }
        
        payload = {
            "username": "ãƒŠãƒŸãƒ¼ãƒ«",
            "embeds": [embed]
        }
        
        try:
            resp = requests.post(self.webhook_url, json=payload)
            resp.raise_for_status()
            logger.info(f"é€šçŸ¥é€ä¿¡æˆåŠŸ: {race_meta['race_id']}")
            return True
        except Exception as e:
            logger.error(f"é€šçŸ¥é€ä¿¡å¤±æ•—: {e}")
            return False

    def _pad_width(self, s: str, width: int) -> str:
        """å…¨è§’æ–‡å­—ã‚’è€ƒæ…®ã—ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ç°¡æ˜“é–¢æ•°"""
        count = 0
        for c in s:
            if ord(c) > 255: count += 2
            else: count += 1
        
        padding = width - count
        if padding > 0:
            return s + " " * padding
        else:
            return s

    def _generate_betting_strategy(self, df: pd.DataFrame) -> str:
        """æ¨å¥¨è²·ã„ç›®ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ (Smart Value Logic)"""
        # 1. ã‚¹ã‚³ã‚¢ä¸Šä½6é ­ã‚’æŠ½å‡º (å®‰å®šç¾¤)
        top_prob_df = df.sort_values('score', ascending=False).head(6)
        
        # 2. ãã®ä¸­ã§æœ€ã‚‚EVãŒé«˜ã„é¦¬ã‚’ã€Œç‹™ã„ç›®ã€ã¨ã™ã‚‹
        best_smart_horse = top_prob_df.sort_values('expected_value', ascending=False).iloc[0]
        
        # 3. ç´”ç²‹ãªå‹ç‡1ä½ (æœ¬å‘½)
        best_prob_horse = top_prob_df.iloc[0]
        
        msg = "**ğŸ« æ¨å¥¨è²·ã„ç›®**\n"
        
        # A. æœ¬å‘½ (å‹ç‡ 1ä½)
        p_num = int(best_prob_horse['horse_number'])
        p_name = best_prob_horse['horse_name']
        p_prob = best_prob_horse['calibrated_prob']
        p_ev = best_prob_horse['expected_value']
        
        msg += f"ğŸ‘‘ **æœ¬å‘½ (å …å®Ÿ)**: {p_num} {p_name}\n"
        msg += f"   (å‹ç‡: {p_prob*100:.1f}%, EV: {p_ev:.2f}) -> å˜å‹/é€£è»¸\n"
        
        # B. ç‹™ã„ç›® (ä¸Šä½5é ­ã®ä¸­ã§Best EV)
        # æœ¬å‘½ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¡¨ç¤º
        if int(best_smart_horse['horse_number']) != p_num:
            v_num = int(best_smart_horse['horse_number'])
            v_name = best_smart_horse['horse_name']
            v_prob = best_smart_horse['calibrated_prob']
            v_ev = best_smart_horse['expected_value']
            
            # EVãŒ1.0ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã®ã¿æ¨å¥¨
            if v_ev > 1.0:
                msg += f"ğŸ’° **ç‹™ã„ç›® (é«˜æœŸå¾…å€¤)**: {v_num} {v_name}\n"
                msg += f"   (å‹ç‡: {v_prob*100:.1f}%, EV: {v_ev:.2f}) -> å˜è¤‡/ãƒ¯ã‚¤ãƒ‰ç›¸æ‰‹\n"
        
        # å…¨ä½“çš„ãªã‚³ãƒ¡ãƒ³ãƒˆ
        if p_ev < 1.0 and best_smart_horse['expected_value'] < 1.0:
            msg += "\nâš ï¸ **å…¨ä½“çš„ã«æœŸå¾…å€¤ä½ã‚ (è¦‹é€ã‚Šæ¨å¥¨)**\n"
            
        return msg

class AutoPredictor:
    def __init__(self, dry_run: bool = False, target_date: str = None):
        self.dry_run = dry_run
        self.target_date = target_date
        self.state_file = STATE_FILE_PATH
        self.notified_races = self._load_state()
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– (åˆå›ã®ã¿ãƒ­ãƒ¼ãƒ‰)
        self.loader = InferenceDataLoader()
        self.preprocessor = InferencePreprocessor()
        self.calibrator = self._load_calibrator()
        self.model = self._load_model() # Ensemble
        
        # Load env vars manually to ensure Webhook URL is present
        load_env_manual()
        webhook_url = os.environ.get('DISCORD_WEBHOOK_URL')
        if not webhook_url:
            logger.error("âŒ DISCORD_WEBHOOK_URL is not set. Notifications will fail.")
            
        self.notifier = NotificationManager(webhook_url)
        
    def _load_state(self) -> set:
        """é€šçŸ¥æ¸ˆã¿ãƒ¬ãƒ¼ã‚¹IDã®èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    return set(json.load(f))
            except:
                return set()
        return set()

    def _save_state(self):
        """é€šçŸ¥æ¸ˆã¿ãƒ¬ãƒ¼ã‚¹IDã®ä¿å­˜"""
        if self.dry_run: return
        
        os.makedirs(os.path.dirname(self.state_file), exist_ok=True)
        with open(self.state_file, 'w') as f:
            json.dump(list(self.notified_races), f)

    def _load_model(self):
        logger.info("ãƒ¢ãƒ‡ãƒ«(Ensemble)ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        model = EnsembleModel()
        model_dir = os.path.join(os.path.dirname(__file__), '../../models')
        # å„ªå…ˆé †ä½: v5 (JRA Specialist)
        path = os.path.join(model_dir, 'ensemble_v5.pkl')
        
        if os.path.exists(path):
            model.load_model(path)
            return model
        else:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
            return None

    def _load_calibrator(self):
        model_dir = os.path.join(os.path.dirname(__file__), '../../models')
        path = os.path.join(model_dir, 'calibrator.pkl')
        if os.path.exists(path):
            try:
                calib = ProbabilityCalibrator() # ã‚¯ãƒ©ã‚¹å®šç¾©æ¸ˆã¿ã¨ä»®å®š
                calib.load(path)
                return calib
            except:
                with open(path, 'rb') as f:
                     # Calibratorã‚¯ãƒ©ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯(pickleç›´èª­ã¿ã¯å±é™ºã ãŒã€calibration.pyã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚’æŒã£ã¦ãã‚‹ã¹ã)
                     pass
                return None
        return None

    def run(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ«ãƒ¼ãƒ—"""
        logger.info("è‡ªå‹•äºˆæ¸¬ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã¾ã™...")
        
        # 1. é–‹å‚¬æ—¥/ç¾åœ¨æ™‚åˆ»ã®å–å¾—
        now = datetime.now()
        if self.target_date:
            today_str = self.target_date.replace('-', '')
        else:
            today_str = now.strftime('%Y%m%d')

        # 2. ãƒ¬ãƒ¼ã‚¹ä¸€è¦§å–å¾—
        race_list_df = self.loader.load_race_list(today_str)
        if race_list_df.empty:
            logger.info("æœ¬æ—¥ã®é–‹å‚¬ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        # 3. ç›´å‰ãƒ¬ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        targets = []
        for _, row in race_list_df.iterrows():
            race_id = row['race_id']
            if race_id in self.notified_races:
                continue
                
            start_time_str = row['start_time']
            if not start_time_str: continue

            try:
                race_dt = datetime.strptime(f"{today_str}{start_time_str}", "%Y%m%d%H%M")
            except ValueError:
                continue

            if self.target_date:
                targets.append(row)
            else:
                diff = race_dt - now
                minutes = diff.total_seconds() / 60
                if 15 <= minutes <= 35:
                     targets.append(row)
        
        if not targets:
            logger.info("ç¾åœ¨ã€ç›´å‰ã®é€šçŸ¥å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
            
        logger.info(f"é€šçŸ¥å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: {len(targets)} ä»¶")

        # 4. æ¨è«– & é€šçŸ¥
        target_ids = [r['race_id'] for r in targets]
        
        try:
            raw_df = self.loader.load(target_date=today_str, race_ids=target_ids)
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return
            
        if raw_df.empty:
            logger.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
            return

        # å‰å‡¦ç†
        X, ids = self.preprocessor.preprocess(raw_df)
        
        # äºˆæ¸¬ (Score)
        try:
            scores = self.model.predict(X)
        except Exception as e:
            logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return

        # Calibration
        if self.calibrator:
            calibrated_probs = self.calibrator.predict(scores)
        else:
            # Softmax Fallback
            calibrated_probs = softmax(scores) # ç°¡æ˜“

        # Normalize to sum to 1.0 (Race-wise)
        # Note: This simple normalization assumes raw_df contains exactly one race or we loop.
        # However, raw_df contains MULTIPLE races.
        # Use pandas groupby transform to normalize per race_id.
        
        # Determine Race IDs for grouping
        # ids df has 'race_id'.
        
        # çµæœçµåˆ
        result_df = ids.copy()
        result_df['score'] = scores
        
        # 1. Softmax (Group by Race)
        # scipy.special.softmax handles array, but we need group-wise
        from scipy.special import softmax
        result_df['prob'] = result_df.groupby('race_id')['score'].transform(lambda x: softmax(x))

        # 2. Calibration
        if self.calibrator:
            result_df['calibrated_prob'] = self.calibrator.predict(result_df['prob'].values)
        else:
            result_df['calibrated_prob'] = result_df['prob']

        # 3. Normalize per Race (Safe-guard)
        race_sums = result_df.groupby('race_id')['calibrated_prob'].transform('sum')
        result_df['calibrated_prob'] = result_df['calibrated_prob'] / race_sums
        
        # EVè¨ˆç®—
        result_df['odds'] = result_df['odds'].replace(0, 1.0)
        result_df['expected_value'] = result_df['calibrated_prob'] * result_df['odds']

        # é€šçŸ¥ãƒ«ãƒ¼ãƒ—
        for race_meta in targets:
            race_id = race_meta['race_id']
            race_df = result_df[result_df['race_id'] == race_id].copy()
            if race_df.empty: continue
            
            venue_map = {
                '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ', '05': 'æ±äº¬', 
                '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½', '09': 'é˜ªç¥', '10': 'å°å€‰'
            }
            venue_code = race_meta['venue']
            race_meta_dict = {
                'race_id': race_id,
                'title': race_meta['title'],
                'race_number': race_meta['race_number'],
                'start_time': race_meta['start_time'][:2] + ":" + race_meta['start_time'][2:],
                'venue_name': venue_map.get(venue_code, 'Unknown'),
                'date': self.target_date if self.target_date else datetime.now().strftime('%Y/%m/%d')
            }
            
            logger.info(f"é€šçŸ¥é€ä¿¡: {race_meta_dict['title']}")
            
            if not self.dry_run:
                success = self.notifier.send_prediction(race_meta_dict, race_df)
                if success:
                    self.notified_races.add(race_id)
                time.sleep(1.0) # Rate Limitå›é¿
            else:
                logger.info("DRY-RUN: é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                print(race_df[['horse_name', 'score', 'calibrated_prob']].sort_values('score', ascending=False).head())

        self._save_state()

def main():
    parser = argparse.ArgumentParser(description='Automated Prediction & Notification')
    parser.add_argument('--dry-run', action='store_true', help='é€šçŸ¥ã‚’é€ä¿¡ã›ãšã«å®Ÿè¡Œ')
    parser.add_argument('--date', type=str, help='å¯¾è±¡æ—¥ä»˜ (YYYYMMDD or YYYY-MM-DD)')
    args = parser.parse_args()
    
    # æ—¥ä»˜æ­£è¦åŒ–
    target_date = args.date
    if target_date and '-' not in target_date:
        # YYYYMMDD -> YYYY-MM-DD
        target_date = f"{target_date[:4]}-{target_date[4:6]}-{target_date[6:]}"

    predictor = AutoPredictor(dry_run=args.dry_run, target_date=target_date)
    predictor.run()

if __name__ == "__main__":
    main()
