import os
import sys
import json
import time
import requests
import argparse
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from scipy.stats import entropy
import pickle

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.model.ensemble import EnsembleModel
from src.inference.preprocessor import InferencePreprocessor
from src.inference.loader import InferenceDataLoader
from src.model.calibration import ProbabilityCalibrator
from src.inference.optimal_strategy import OptimalStrategy

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(os.path.join(os.path.dirname(__file__), '../../logs/auto_predict.log'))
    ]
)
logger = logging.getLogger(__name__)


# .env æ‰‹å‹•èª­ã¿è¾¼ã¿
def load_env_manual():
    try:
        env_path = os.path.join(os.path.dirname(__file__), '../../.env')
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'): continue
                    if '=' in line:
                        key, val = line.split('=', 1)
                        os.environ[key.strip()] = val.strip()
    except Exception as e:
        logger.warning(f".env reading failed: {e}")

# å®šæ•°
STATE_FILE_PATH = os.path.join(os.path.dirname(__file__), '../../data/state/notified_races.json')

class NotificationManager:
    """Discordé€šçŸ¥ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url

    def _calculate_confidence(self, df: pd.DataFrame) -> tuple[str, str]:
        """ãƒã‚¶ãƒ¼ãƒ‰(æ³¢ä¹±åº¦)ã¨è‡ªä¿¡åº¦ã‚’åˆ¤å®š"""
        # å‹ç‡åˆ†å¸ƒã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
        probs = df['calibrated_prob'].values
        ent = entropy(probs)
        
        top_horse = df.sort_values('score', ascending=False).iloc[0]
        top_prob = top_horse['calibrated_prob']
        top_score = top_horse['score']
        
        # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        if top_prob >= 0.40 or top_score >= 1.5:
            return "S", "é‰„æ¿ (Ironclad)"
        elif top_prob >= 0.25 or top_score >= 0.8:
            return "A", "å®‰å®š (Stable)"
        elif ent > 2.0 or top_prob < 0.20:
             return "C", "æ³¢ä¹± (High Chaos)"
        else:
             return "B", "æ··æˆ¦ (Confusion)"

    def send_prediction(self, race_meta: Dict, df: pd.DataFrame):
        """
        äºˆæ¸¬çµæœã‚’Discordã«é€ä¿¡ã—ã¾ã™ã€‚
        Args:
            race_meta: ãƒ¬ãƒ¼ã‚¹æƒ…å ±
            df: äºˆæ¸¬çµæœDataFrame
        Returns:
            bool: é€ä¿¡æˆåŠŸãªã‚‰True
        """
        if not self.webhook_url:
            logger.warning("Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return False

        # ã‚¿ã‚¤ãƒˆãƒ«æ•´å½¢
        date_str = race_meta.get('date', '')
        
        # æ³¢ä¹±åº¦åˆ¤å®š
        chart_rank, chart_desc = self._calculate_confidence(df)
        
        title_str = f"ğŸ¯ [{date_str}] {race_meta['venue_name']}{race_meta['race_number']}R {race_meta['title']} ({race_meta['start_time']}) - [{chart_rank}] {chart_desc}"

        # äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ (å…¨é ­: ã‚¹ã‚³ã‚¢é † -> æœ€ã‚‚ç´”ç²‹ãªå¼·ã•è©•ä¾¡)
        top_picks = df.sort_values('score', ascending=False)
        
        description = "**ğŸ† æœ¬å‘½äºˆæ¸¬ (ã‚¹ã‚³ã‚¢é †)**\n"
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã€ãƒªã‚¹ãƒˆå½¢å¼ã§è¦‹ã‚„ã™ã
        
        for i, (_, row) in enumerate(top_picks.iterrows()):
            h_num = str(int(row['horse_number'])).zfill(2)
            h_name = row['horse_name']
            
            ev = f"{row['expected_value']:.2f}"
            prob = f"{row['calibrated_prob']*100:.0f}%"
            score = f"{row['score']:.2f}"
            
            # Simple list format without Mark
            description += f"`{h_num}` **{h_name}** (å‹ç‡:{prob}, EV:{ev}, Sc:{score})\n"

        # æ¨å¥¨è²·ã„ç›® (Smart Value Logic)
        bet_strategy = self._generate_betting_strategy(df)
        
        # NetKeiba Link
        # IDå½¢å¼è£œæ­£: YYYY(4) + Venue(2) + Kai(2) + Nichi(2) + R(2) 
        # race_meta['race_id'] ã¯é€šå¸¸ã“ã®å½¢å¼ã€‚
        netkeiba_url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_meta['race_id']}"
        description += f"\nğŸ”— [NetKeiba]({netkeiba_url})\n"
        
        embed = {
            "title": title_str,
            "description": description + "\n" + bet_strategy,
            "color": 0xFF0000 if top_picks.iloc[0]['expected_value'] > 1.5 else (0x00FF00 if chart_rank in ['S', 'A'] else 0xFFA500), # S/Aãªã‚‰ç·‘ã€ãã‚Œä»¥å¤–ã¯ã‚ªãƒ¬ãƒ³ã‚¸ã€é«˜EVã¯èµ¤
            "footer": {
                "text": "Keiiba-AI Prediction System"
            }
        }
        
        payload = {
            "username": "ãƒŠãƒŸãƒ¼ãƒ«",
            "embeds": [embed]
        }
        
        try:
            resp = requests.post(self.webhook_url, json=payload)
            resp.raise_for_status()
            logger.info(f"é€šçŸ¥é€ä¿¡æˆåŠŸ: {race_meta['race_id']}")
            return True
        except Exception as e:
            logger.error(f"é€šçŸ¥é€ä¿¡å¤±æ•—: {e}")
            return False

    def _pad_width(self, s: str, width: int) -> str:
        """å…¨è§’æ–‡å­—ã‚’è€ƒæ…®ã—ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ç°¡æ˜“é–¢æ•°"""
        count = 0
        for c in s:
            if ord(c) > 255: count += 2
            else: count += 1
        
        padding = width - count
        if padding > 0:
            return s + " " * padding
        else:
            return s

    def _calculate_betting_data(self, df: pd.DataFrame) -> dict:
        """æ¨å¥¨è²·ã„ç›®ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã—ã¦è¿”ã™ (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨)"""
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ (åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨)
        sorted_df = df.sort_values('score', ascending=False)
        top1 = sorted_df.iloc[0]
        
        # åŸºæœ¬æƒ…å ±
        top1_ev = top1.get('expected_value', 0)
        h_num = int(top1['horse_number'])
        h_str = f"{h_num:02}"
        
        # ç›¸æ‰‹é¦¬ (Rank 2-6)
        opps = sorted_df.iloc[1:6] 
        opp_nums = [f"{int(x):02}" for x in opps['horse_number']]
        
        strategy_data = {
            "top1": top1,
            "sorted_df": sorted_df,
            "ev": top1_ev,
            "bets": [],
            "strategy_type": "Low",
            "is_strong": False
        }
        
        # æˆ¦ç•¥åˆ¤å®š
        if top1_ev >= 1.2:
            # High Value
            strategy_data["strategy_type"] = "High"
            # ä¸‰é€£è¤‡ 1é ­è»¸æµã— (Rank 2,3,4)
            strategy_data["bets"].append({
                "type": "sanrenpuku",
                "axis": [h_num],
                "partners": [int(x) for x in opps.iloc[:3]['horse_number']],
                "points": 3
            })
            
        elif top1_ev >= 0.8:
            # Mid Value
            strategy_data["strategy_type"] = "Mid"
            # ä¸‰é€£å˜ 1ç€å›ºå®šæµã— (Rank 2,3,4)
            strategy_data["bets"].append({
                "type": "sanrentan_1fix",
                "axis": [h_num],
                "partners": [int(x) for x in opps.iloc[:3]['horse_number']],
                "points": 6
            })
            # (å‚è€ƒ) é¦¬é€£ 1é ­è»¸æµã— (Rank 2,3,4,5)
            # strategy_data["bets"].append({
            #     "type": "umaren",
            #     "axis": [h_num],
            #     "partners": [int(x) for x in opps.iloc[:4]['horse_number']],
            #     "points": 4
            # })
            
        else:
            # Low Value (è¦‹é€ã‚Š)
            strategy_data["strategy_type"] = "Low"
        
        # å¼·æ°—é¦¬åˆ¸åˆ¤å®š (7ç•ªäººæ°—ä»¥ä¸Š)
        axis_pop = int(top1['popularity']) if pd.notna(top1['popularity']) else 99
        if axis_pop >= 7:
            strategy_data["is_strong"] = True
            # ä¸‰é€£å˜ 1ç€å›ºå®šæµã— (Rank 2,3,4,5) -> Opps has 5 horses (Rank 2-6). 
            # Original code said: {','.join(opp_nums[:4])} which is Rank 2,3,4,5.
            strategy_data["bets"].append({
                "type": "sanrentan_1fix_strong",
                "axis": [h_num],
                "partners": [int(x) for x in opps.iloc[:4]['horse_number']],
                "points": 12
            })
            
        return strategy_data

    def _generate_betting_strategy(self, df: pd.DataFrame) -> str:
        """æ¨å¥¨è²·ã„ç›®ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ (v12 æœ€é©æˆ¦ç•¥)"""
        data = self._calculate_betting_data(df)
        sorted_df = data["sorted_df"]
        
        # --- 1. AIæœ¬å‘½äºˆæƒ³ãƒªã‚¹ãƒˆ ---
        msg = "**ğŸ¤– AIæœ¬å‘½äºˆæƒ³ (Ranked v12)**\n"
        symbols = ['â—', 'ã€‡', 'â–²', 'â–³', 'â–³', 'â–³', 'æ³¨']
        
        # ä¸Šä½7é ­ã‚’è¡¨ç¤º
        for i, (idx, row) in enumerate(sorted_df.head(7).iterrows()):
            h_num = str(int(row['horse_number'])).zfill(2)
            ev = row.get('expected_value', 0)
            score = row.get('score', 0)
            pop = int(row['popularity']) if pd.notna(row['popularity']) else 99
            short_name = str(row['horse_name'])[:5]
            symbol = symbols[i] if i < len(symbols) else '  '
            msg += f"`{symbol}{h_num} {short_name:<5}({pop}äºº) S{score:.2f} E{ev:.2f}`\n"
            
        msg += "\n"
        
        # --- 2. æ¨å¥¨è²·ã„ç›® (v12 Logic) ---
        msg += "**ğŸ“ˆ æ¨å¥¨è²·ã„ç›® (v12æˆ¦ç•¥)**\n"
        
        top1 = data["top1"]
        h_str = f"{int(top1['horse_number']):02}"
        # Rank 2-6 IDs for display
        opps = sorted_df.iloc[1:6]
        opp_nums = [f"{int(x):02}" for x in opps['horse_number']]
        
        if data["strategy_type"] == "High":
            msg += f"ğŸ”¥ **High Value (EV {data['ev']:.2f})** - é‰„æ¿/é«˜å¦™å‘³\n"
            msg += f"âœ… **æ¨å¥¨: ä¸‰é€£è¤‡ 1é ­è»¸æµã— (3ç‚¹)**\n"
            msg += f"`{h_str} - {','.join(opp_nums[:3])}` (ç›¸æ‰‹: 2,3,4ä½)\n"
            msg += "â€»æœŸå¾…å€¤ãŒé«˜ã„ãŸã‚ã€ä¸‰é€£è¤‡3ç‚¹ã§é«˜å›å(142%)ã‚’ç‹™ã„ã¾ã™ã€‚\n"
            
        elif data["strategy_type"] == "Mid":
            msg += f"âœ¨ **Mid Value (EV {data['ev']:.2f})** - ä¸­å¦™å‘³\n"
            msg += f"âœ… **æ¨å¥¨: ä¸‰é€£å˜ 1ç€å›ºå®šæµã— (6ç‚¹)**\n"
            msg += f"`{h_str} -> {','.join(opp_nums[:3])}` (ç›¸æ‰‹: 2,3,4ä½)\n"
            msg += f"ğŸ’¡ (å®‰å®š) é¦¬é€£ 1é ­è»¸æµã— (4ç‚¹): `{h_str} - {','.join(opp_nums[:4])}`\n"
            
        else:
            msg += f"âš ï¸ **Low Value (EV {data['ev']:.2f})** - ä½å¦™å‘³ (è¦‹é€ã‚Šæ¨å¥¨)\n"
            msg += "éå‰°äººæ°—ã®ãŸã‚ã€æœŸå¾…å€¤ãŒä½ã„ã§ã™ã€‚åŸºæœ¬ã¯ã‚±ãƒ³(è¦‹é€ã‚Š)ã—ã¦ãã ã•ã„ã€‚\n"
            msg += f"(å‚è€ƒ) ä¸‰é€£å˜ 1ç€å›ºå®šæµã— (6ç‚¹): `{h_str} -> {','.join(opp_nums[:3])}`\n"
        
        # --- 3. å¼·æ°—é¦¬åˆ¸ ---
        if data["is_strong"]:
            axis_pop = int(top1['popularity']) if pd.notna(top1['popularity']) else 99
            msg += "\n"
            msg += f"ğŸ”¥ **å¼·æ°—é¦¬åˆ¸** (Top1ãŒ{axis_pop}ç•ªäººæ°—)\n"
            msg += f"âœ… **ä¸‰é€£å˜ 1ç€å›ºå®šæµã—: {h_str}â†’{','.join(opp_nums[:4])}** (12ç‚¹)\n"
            msg += "â€»ç©´ç‹™ã„ã§é«˜é…å½“ã‚’ç‹™ãˆã‚‹æ¡ä»¶ã§ã™ã€‚\n"
        
        return msg

class AutoPredictor:
    def __init__(self, dry_run: bool = False, target_date: str = None):
        self.dry_run = dry_run
        self.target_date = target_date
        self.state_file = STATE_FILE_PATH
        self.notified_races = self._load_state()
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– (åˆå›ã®ã¿ãƒ­ãƒ¼ãƒ‰)
        self.loader = InferenceDataLoader()
        self.preprocessor = InferencePreprocessor()
        self.calibrator = self._load_calibrator()
        self.model = self._load_model() # Ensemble
        
        # v12ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã®ãƒ­ãƒ¼ãƒ‰
        self.expected_features = self._load_feature_list()
        
        # Load env vars manually to ensure Webhook URL is present
        load_env_manual()
        webhook_url = os.environ.get('DISCORD_WEBHOOK_URL')
        if not webhook_url:
            logger.error("âŒ DISCORD_WEBHOOK_URL is not set. Notifications will fail.")
            
        self.notifier = NotificationManager(webhook_url)
        
    def _load_state(self) -> set:
        """é€šçŸ¥æ¸ˆã¿ãƒ¬ãƒ¼ã‚¹IDã®èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    return set(json.load(f))
            except:
                return set()
        return set()

    def _save_state(self):
        """é€šçŸ¥æ¸ˆã¿ãƒ¬ãƒ¼ã‚¹IDã®ä¿å­˜"""
        if self.dry_run: return
        
        os.makedirs(os.path.dirname(self.state_file), exist_ok=True)
        with open(self.state_file, 'w') as f:
            json.dump(list(self.notified_races), f)

    def _load_model(self):
        logger.info("ãƒ¢ãƒ‡ãƒ«(Ensemble v12: TabNet Revival)ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        model = EnsembleModel()
        # v12ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ (experimentsé…ä¸‹)
        model_path = os.path.join(os.path.dirname(__file__), '../../experiments/v12_tabnet_revival/models/ensemble.pkl')
        
        if os.path.exists(model_path):
            model.load_model(model_path, device_name='cpu') # æ¨è«–ã¯CPUã§å®‰å…¨ã«
            return model
        else:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (models/ensemble_v7.pkl)
            fallback_path = os.path.join(os.path.dirname(__file__), '../../models/ensemble_v7.pkl')
            if os.path.exists(fallback_path):
                 logger.warning("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«(v7)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                 model.load_model(fallback_path)
                 return model
            return None

    def _load_feature_list(self):
        """v12ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: LightGBMãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å–å¾—)"""
        import json
        features_path = os.path.join(os.path.dirname(__file__), 
            '../../experiments/v12_tabnet_revival/models/tabnet.features.json')
        if os.path.exists(features_path):
            try:
                with open(features_path, 'r', encoding='utf-8') as f:
                    features = json.load(f)
                logger.info(f"v12ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ (JSON): {len(features)}å€‹")
                return features
            except Exception as e:
                logger.warning(f"ç‰¹å¾´é‡JSONã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}. LightGBMã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
        
        # Fallback: LightGBM model's feature_name()
        if self.model and hasattr(self.model, 'lgbm') and self.model.lgbm:
            try:
                lgbm_booster = self.model.lgbm.model  # lightgbm.Booster
                if hasattr(lgbm_booster, 'feature_name'):
                    features = lgbm_booster.feature_name()
                    logger.info(f"v12ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ (LightGBM): {len(features)}å€‹")
                    return features
            except Exception as e:
                logger.warning(f"LightGBMã‹ã‚‰ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}")
        
        logger.warning("ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç‰¹å¾´é‡é©åˆãªã—ã§æ¨è«–ã—ã¾ã™ã€‚")
        return None

    def _load_calibrator(self):
        model_dir = os.path.join(os.path.dirname(__file__), '../../models')
        path = os.path.join(model_dir, 'calibrator.pkl')
        if os.path.exists(path):
            try:
                calib = ProbabilityCalibrator() # ã‚¯ãƒ©ã‚¹å®šç¾©æ¸ˆã¿ã¨ä»®å®š
                calib.load(path)
                return calib
            except:
                with open(path, 'rb') as f:
                     # Calibratorã‚¯ãƒ©ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯(pickleç›´èª­ã¿ã¯å±é™ºã ãŒã€calibration.pyã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚’æŒã£ã¦ãã‚‹ã¹ã)
                     pass
                return None
        return None

    def run(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ«ãƒ¼ãƒ—"""
        logger.info("è‡ªå‹•äºˆæ¸¬ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã¾ã™...")
        
        # 1. é–‹å‚¬æ—¥/ç¾åœ¨æ™‚åˆ»ã®å–å¾—
        now = datetime.now()
        if self.target_date:
            today_str = self.target_date.replace('-', '')
        else:
            today_str = now.strftime('%Y%m%d')

        # 2. ãƒ¬ãƒ¼ã‚¹ä¸€è¦§å–å¾—
        race_list_df = self.loader.load_race_list(today_str)
        if race_list_df.empty:
            logger.info("æœ¬æ—¥ã®é–‹å‚¬ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        # 3. ç›´å‰ãƒ¬ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        targets = []
        for _, row in race_list_df.iterrows():
            race_id = row['race_id']
            if race_id in self.notified_races:
                continue
                
            start_time_str = row['start_time']
            if not start_time_str: continue
            
            # ã‚³ãƒ­ãƒ³ã‚’é™¤å» ("09:45" â†’ "0945")
            start_time_str = str(start_time_str).replace(':', '')

            try:
                race_dt = datetime.strptime(f"{today_str}{start_time_str}", "%Y%m%d%H%M")
            except ValueError:
                continue

            if self.target_date:
                targets.append(row)
            else:
                diff = race_dt - now
                minutes = diff.total_seconds() / 60
                if 15 <= minutes <= 35:
                     targets.append(row)
        
        if not targets:
            logger.info("ç¾åœ¨ã€ç›´å‰ã®é€šçŸ¥å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
            
        logger.info(f"é€šçŸ¥å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: {len(targets)} ä»¶")

        # 4. æ¨è«– & é€šçŸ¥
        target_ids = [r['race_id'] for r in targets]
        
        try:
            raw_df = self.loader.load(target_date=today_str, race_ids=target_ids)
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return
            
        if raw_df.empty:
            logger.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
            return

        # å‰å‡¦ç†
        X, ids = self.preprocessor.preprocess(raw_df)
        
        # ç‰¹å¾´é‡ã‚¢ãƒ€ãƒ—ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ (v12ãƒ¢ãƒ‡ãƒ«ç”¨)
        if self.expected_features:
            missing = set(self.expected_features) - set(X.columns)
            if missing:
                logger.warning(f"ä¸è¶³ç‰¹å¾´é‡ã‚’0ã§è£œå®Œ: {len(missing)}å€‹")
                for col in missing:
                    X[col] = 0.0
            # ç‰¹å¾´é‡ã®é †åºã‚’æƒãˆã‚‹
            X = X[[c for c in self.expected_features if c in X.columns]]
        
        # äºˆæ¸¬ (Score)
        try:
            scores = self.model.predict(X)
        except Exception as e:
            logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return

        # Calibration
        if self.calibrator:
            calibrated_probs = self.calibrator.predict(scores)
        else:
            # Softmax Fallback
            calibrated_probs = softmax(scores) # ç°¡æ˜“

        # Normalize to sum to 1.0 (Race-wise)
        # Note: This simple normalization assumes raw_df contains exactly one race or we loop.
        # However, raw_df contains MULTIPLE races.
        # Use pandas groupby transform to normalize per race_id.
        
        # Determine Race IDs for grouping
        # ids df has 'race_id'.
        
        # çµæœçµåˆ
        result_df = ids.copy()
        result_df['score'] = scores
        
        # 1. Softmax (Group by Race) with Temperature to avoid extreme probabilities
        # Temperature > 1.0 makes distribution more uniform
        from scipy.special import softmax
        SOFTMAX_TEMPERATURE = 3.0  # ã‚¹ã‚³ã‚¢å·®ãŒæ¥µç«¯ãªå ´åˆã®ç·©å’Œç”¨
        result_df['prob'] = result_df.groupby('race_id')['score'].transform(
            lambda x: softmax(x / SOFTMAX_TEMPERATURE)
        )

        # 2. Calibration
        if self.calibrator:
            result_df['calibrated_prob'] = self.calibrator.predict(result_df['prob'].values)
        else:
            result_df['calibrated_prob'] = result_df['prob']

        # 3. Normalize per Race (Safe-guard)
        race_sums = result_df.groupby('race_id')['calibrated_prob'].transform('sum')
        result_df['calibrated_prob'] = result_df['calibrated_prob'] / race_sums
        
        # EVè¨ˆç®—
        result_df['odds'] = result_df['odds'].replace(0, 1.0)
        result_df['expected_value'] = result_df['calibrated_prob'] * result_df['odds']

        # é€šçŸ¥ãƒ«ãƒ¼ãƒ—
        for race_meta in targets:
            race_id = race_meta['race_id']
            race_df = result_df[result_df['race_id'] == race_id].copy()
            if race_df.empty: continue
            
            venue_map = {
                '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ', '05': 'æ±äº¬', 
                '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½', '09': 'é˜ªç¥', '10': 'å°å€‰'
            }
            venue_code = race_meta['venue']
            race_meta_dict = {
                'race_id': race_id,
                'title': race_meta['title'],
                'race_number': race_meta['race_number'],
                'start_time': race_meta['start_time'][:2] + ":" + race_meta['start_time'][2:],
                'venue_name': venue_map.get(venue_code, 'Unknown'),
                'date': self.target_date if self.target_date else datetime.now().strftime('%Y/%m/%d')
            }
            
            logger.info(f"é€šçŸ¥é€ä¿¡: {race_meta_dict['title']}")
            
            if not self.dry_run:
                success = self.notifier.send_prediction(race_meta_dict, race_df)
                if success:
                    self.notified_races.add(race_id)
                time.sleep(1.0) # Rate Limitå›é¿
            else:
                logger.info("DRY-RUN: é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                print(race_df[['horse_name', 'score', 'calibrated_prob']].sort_values('score', ascending=False).head())

        self._save_state()

def main():
    parser = argparse.ArgumentParser(description='Automated Prediction & Notification')
    parser.add_argument('--dry-run', action='store_true', help='é€šçŸ¥ã‚’é€ä¿¡ã›ãšã«å®Ÿè¡Œ')
    parser.add_argument('--date', type=str, help='å¯¾è±¡æ—¥ä»˜ (YYYYMMDD or YYYY-MM-DD)')
    args = parser.parse_args()
    
    # æ—¥ä»˜æ­£è¦åŒ–
    target_date = args.date
    if target_date and '-' not in target_date:
        # YYYYMMDD -> YYYY-MM-DD
        target_date = f"{target_date[:4]}-{target_date[4:6]}-{target_date[6:]}"

    predictor = AutoPredictor(dry_run=args.dry_run, target_date=target_date)
    predictor.run()

if __name__ == "__main__":
    main()
