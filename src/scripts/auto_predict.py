# ... (Imports remain mostly the same, ensuring all needed are present)
import os
import sys
import json
import time
import requests
import argparse
import pandas as pd
import numpy as np
import logging
import pickle
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from scipy.special import softmax
from scipy.stats import entropy
from itertools import combinations, permutations

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.inference.preprocessor import InferencePreprocessor
from src.inference.loader import InferenceDataLoader
from src.model.calibration import ProbabilityCalibrator

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(os.path.join(os.path.dirname(__file__), '../../logs/auto_predict.log'))
    ]
)
logger = logging.getLogger(__name__)

# .env æ‰‹å‹•èª­ã¿è¾¼ã¿
def load_env_manual():
    try:
        env_path = os.path.join(os.path.dirname(__file__), '../../.env')
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'): continue
                    if '=' in line:
                        key, val = line.split('=', 1)
                        os.environ[key.strip()] = val.strip()
    except Exception as e:
        logger.warning(f".env reading failed: {e}")

# å®šæ•°
STATE_FILE_PATH = os.path.join(os.path.dirname(__file__), '../../data/state/notified_races.json')
RULES_PATH = os.path.join(os.path.dirname(__file__), '../../experiments/v23_regression_cv/final_rules_v23.json')
MODEL_DIR = os.path.join(os.path.dirname(__file__), '../../experiments/v23_regression_cv/fold4')

class NotificationManager:
    """Discordé€šçŸ¥ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, webhook_url: str, rules: list):
        self.webhook_url = webhook_url
        self.rules = rules

    def _calculate_confidence(self, df: pd.DataFrame) -> tuple[str, str]:
        """ãƒã‚¶ãƒ¼ãƒ‰(æ³¢ä¹±åº¦)ã¨è‡ªä¿¡åº¦ã‚’åˆ¤å®š"""
        probs = df['prob'].values 
        ent = entropy(probs)
        
        top_horse = df.sort_values('score', ascending=False).iloc[0]
        # v23 score is regression (race normalized?) No, raw score.
        # But we calculate prob using softmax.
        top_prob = top_horse['prob']
        
        if top_prob >= 0.40:
            return "S", "é‰„æ¿ (Ironclad)"
        elif top_prob >= 0.25:
            return "A", "å®‰å®š (Stable)"
        elif ent > 2.0 or top_prob < 0.20:
             return "C", "æ³¢ä¹± (High Chaos)"
        else:
             return "B", "æ··æˆ¦ (Confusion)"

    def send_prediction(self, race_meta: Dict, df: pd.DataFrame, race_features: Dict):
        """äºˆæ¸¬çµæœã‚’Discordã«é€ä¿¡"""
        if not self.webhook_url:
            return False

        date_str = race_meta.get('date', '')
        chart_rank, chart_desc = self._calculate_confidence(df)
        
        title_str = f"ğŸ¯ [{date_str}] {race_meta['venue_name']}{race_meta['race_number']}R {race_meta['title']} ({race_meta['start_time']}) - [{chart_rank}] {chart_desc}"

        # 1. äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«
        top_picks = df.sort_values('score', ascending=False)
        description = "**ğŸ† æœ¬å‘½äºˆæ¸¬ (v23 Model)**\n"
        
        for i, (_, row) in enumerate(top_picks.iterrows()):
            h_num = str(int(row['horse_number'])).zfill(2)
            h_name = row['horse_name']
            
            # v23ã¯å›å¸°ã‚¹ã‚³ã‚¢ãªã®ã§ãã®ã¾ã¾è¡¨ç¤º
            score = f"{row['score']:.2f}"
            prob_val = row.get('prob', 0)
            prob = f"{prob_val*100:.0f}%"
            
            odds_str = f"{row['odds']:.1f}" if row['odds'] > 0 else "-"
            
            description += f"`{h_num}` **{h_name}** (Odds:{odds_str}, Sc:{score}, Win%:{prob})\n"

        # 2. æ¨å¥¨è²·ã„ç›®
        bet_msg = self._generate_betting_strategy(df, race_features)
        
        # NetKeiba Link
        netkeiba_url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_meta['race_id']}"
        description += f"\nğŸ”— [NetKeiba]({netkeiba_url})\n"
        
        embed = {
            "title": title_str,
            "description": description + "\n" + bet_msg,
            "color": 0x00FF00 if chart_rank in ['S', 'A'] else 0xFFA500,
            "footer": {
                "text": "Keiiba-AI v23 (Auto-Optimized)"
            }
        }
        
        payload = {"username": "ãƒŠãƒŸãƒ¼ãƒ« (v23)", "embeds": [embed]}
        
        try:
            resp = requests.post(self.webhook_url, json=payload)
            resp.raise_for_status()
            logger.info(f"é€šçŸ¥é€ä¿¡æˆåŠŸ: {race_meta['race_id']}")
            return True
        except Exception as e:
            logger.error(f"é€šçŸ¥é€ä¿¡å¤±æ•—: {e}")
            return False

    def _generate_betting_strategy(self, df: pd.DataFrame, features: Dict) -> str:
        """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§æ¨å¥¨è²·ã„ç›®ã‚’ç”Ÿæˆ"""
        # ãƒ«ãƒ¼ãƒ«é©ç”¨
        valid_bets = []
        
        # features ã¯ race_level ã®ç‰¹å¾´é‡ (score_gap, etc)
        # ãƒ«ãƒ¼ãƒ«æ¡ä»¶ãƒã‚§ãƒƒã‚¯
        for rule in self.rules:
            match = True
            for feat, op, thres in rule['conditions']:
                val = features.get(feat, 0)
                if op == '<=':
                    if not (val <= thres):
                        match = False; break
                else:
                    if not (val > thres):
                        match = False; break
            if match:
                valid_bets.append(rule)
        
        if not valid_bets:
            return "âš ï¸ **æ¨å¥¨è²·ã„ç›®ãªã— (æ¡ä»¶ä¸ä¸€è‡´)**\næ§˜å­è¦‹æ¨å¥¨ã§ã™ã€‚\n"

        msg = "**ğŸ“ˆ æ¨å¥¨è²·ã„ç›® (AI Optimized Rules)**\n"
        
        # Betting Logic (Generate codes)
        top_horses = df.sort_values('score', ascending=False)['horse_number'].astype(int).tolist()
        
        # é‡è¤‡é™¤å¤–ã—ã¦è¡¨ç¤º
        shown_bets = set()
        
        # ãƒ«ãƒ¼ãƒ«ã”ã¨ã®è¡¨ç¤º
        # å„ªå…ˆåº¦é †ã«ä¸¦ã¹æ›¿ãˆãŸã„ãŒã€JSONé †åº(ROIé«˜ã„é †)ã¨ä»®å®š
        for rule in valid_bets:
            bname = rule['bet_name']
            if bname in shown_bets: continue
            
            # ROIãªã©ã®è£œè¶³æƒ…å ±
            roi = rule.get('roi', 0) * 100
            msg += f"âœ… **{bname}** (æœŸå¾…ROI {roi:.0f}%)\n"
            
            # å®Ÿéš›ã®è²·ã„ç›®æ§‹ç¯‰ (ç°¡æ˜“)
            codes_str = self._format_bet_codes(bname, top_horses)
            if codes_str:
                msg += f"`{codes_str}`\n"
            
            shown_bets.add(bname)
            
        return msg

    def _format_bet_codes(self, bname, top_horses):
        """è²·ã„ç›®ã®æ–‡å­—åˆ—è¡¨ç¾ã‚’ç”Ÿæˆ"""
        try:
            if 'tansho' in bname:
                return f"å˜å‹: {top_horses[0]:02}"
            elif 'umaren_box' in bname:
                n = int(bname[-1])
                return f"é¦¬é€£BOX: {','.join([f'{x:02}' for x in top_horses[:n]])}"
            elif 'umaren_nagashi' in bname:
                return f"é¦¬é€£æµã—: {top_horses[0]:02} - {','.join([f'{x:02}' for x in top_horses[1:5]])}"
            elif 'wide_box' in bname:
                n = int(bname[-1])
                return f"ãƒ¯ã‚¤ãƒ‰BOX: {','.join([f'{x:02}' for x in top_horses[:n]])}"
            elif 'wide_nagashi' in bname:
                 return f"ãƒ¯ã‚¤ãƒ‰æµã—: {top_horses[0]:02} - {','.join([f'{x:02}' for x in top_horses[1:5]])}"
            elif 'umatan_1st' in bname:
                return f"é¦¬å˜1ç€å›ºå®š: {top_horses[0]:02} -> {','.join([f'{x:02}' for x in top_horses[1:5]])}"
            elif 'umatan_box' in bname:
                n = int(bname[-1])
                return f"é¦¬å˜BOX: {','.join([f'{x:02}' for x in top_horses[:n]])}"
            elif 'sanrenpuku_box' in bname:
                n = int(bname[-1])
                return f"ä¸‰é€£è¤‡BOX: {','.join([f'{x:02}' for x in top_horses[:n]])}"
            elif 'sanrenpuku_nagashi' in bname:
                return f"ä¸‰é€£è¤‡æµã—: {top_horses[0]:02} - {','.join([f'{x:02}' for x in top_horses[1:5]])} (2é ­)"
            elif 'sanrentan_1st' in bname:
                return f"ä¸‰é€£å˜1ç€å›ºå®š: {top_horses[0]:02} -> {','.join([f'{x:02}' for x in top_horses[1:5]])} (M)"
            elif 'sanrentan_box' in bname:
                n = int(bname[-1])
                return f"ä¸‰é€£å˜BOX: {','.join([f'{x:02}' for x in top_horses[:n]])}"
            return bname
        except:
            return f"Error formatting {bname}"

class AutoPredictor:
    def __init__(self, dry_run: bool = False, target_date: str = None):
        self.dry_run = dry_run
        self.target_date = target_date
        self.state_file = STATE_FILE_PATH
        self.notified_races = self._load_state()
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.loader = InferenceDataLoader()
        self.preprocessor = InferencePreprocessor()
        self.lgbm, self.catboost, self.meta = self._load_v23_models()
        self.rules = self._load_rules()
        
        # Load env vars manually to ensure Webhook URL is present
        load_env_manual()
        webhook_url = os.environ.get('DISCORD_WEBHOOK_URL')
        if not webhook_url:
            logger.error("âŒ DISCORD_WEBHOOK_URL is not set.")
            
        self.notifier = NotificationManager(webhook_url, self.rules)
        
    def _load_state(self) -> set:
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f: return set(json.load(f))
            except: return set()
        return set()

    def _save_state(self):
        if self.dry_run: return
        os.makedirs(os.path.dirname(self.state_file), exist_ok=True)
        with open(self.state_file, 'w') as f: json.dump(list(self.notified_races), f)

    def _load_v23_models(self):
        logger.info(f"Loading v23 models from {MODEL_DIR}...")
        try:
            with open(os.path.join(MODEL_DIR, 'lgbm_v23.pkl'), 'rb') as f: lgbm = pickle.load(f)
            with open(os.path.join(MODEL_DIR, 'catboost_v23.pkl'), 'rb') as f: catboost = pickle.load(f)
            with open(os.path.join(MODEL_DIR, 'meta_v23.pkl'), 'rb') as f: meta = pickle.load(f)
            return lgbm, catboost, meta
        except Exception as e:
            logger.error(f"Failed to load models: {e}")
            sys.exit(1)

    def _load_rules(self):
        if not os.path.exists(RULES_PATH):
            logger.warning("Rules file not found.")
            return []
        with open(RULES_PATH, 'r') as f: return json.load(f)

    def run(self):
        logger.info("AutoPredict v23 Process Start...")
        
        now = datetime.now()
        today_str = self.target_date.replace('-', '') if self.target_date else now.strftime('%Y%m%d')

        # 1. ãƒ¬ãƒ¼ã‚¹ä¸€è¦§
        try:
            race_list_df = self.loader.load_race_list(today_str)
        except Exception as e:
            logger.error(f"Race list load failed: {e}")
            return

        # Prepare venue_name
        venue_map = {
            '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ', '05': 'æ±äº¬', 
            '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½', '09': 'é˜ªç¥', '10': 'å°å€‰'
        }
        race_list_df['venue_name'] = race_list_df['venue'].map(venue_map).fillna(race_list_df['venue'])

        if race_list_df.empty:
            logger.info("No races today.")
            return

        # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (15-35åˆ†å‰)
        targets = []
        for _, row in race_list_df.iterrows():
            race_id = row['race_id']
            if race_id in self.notified_races: continue
                
            start_time_str = str(row['start_time']).replace(':', '')
            try:
                race_dt = datetime.strptime(f"{today_str}{start_time_str}", "%Y%m%d%H%M")
            except: continue

            if self.target_date:
                targets.append(row)
            else:
                diff = race_dt - now
                minutes = diff.total_seconds() / 60
                if 15 <= minutes <= 35:
                     targets.append(row)
        
        if not targets:
            logger.info("No target races for notification.")
            return

        logger.info(f"Targets: {len(targets)} races")

        # 3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»æ¨è«–
        target_ids = [r['race_id'] for r in targets]
        raw_df = self.loader.load(target_date=today_str, race_ids=target_ids)
        if raw_df.empty: return

        # å‰å‡¦ç†
        X, ids = self.preprocessor.preprocess(raw_df)
        
        # ç‰¹å¾´é‡è£œå®Œ (v23ãƒ¢ãƒ‡ãƒ«ç”¨)
        # pickleãªã©ã‹ã‚‰ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã®ãŒæ­£é“ã ãŒã€ç°¡æ˜“çš„ã«LGBMã‹ã‚‰å–å¾—
        expected_cols = self.lgbm.feature_name()
        
        # ã‚«ãƒ©ãƒ åˆã‚ã›
        for col in expected_cols:
            if col not in X.columns: X[col] = 0.0
        X = X[expected_cols]

        # æ¨è«– (Ensemble)
        try:
            p1 = self.lgbm.predict(X)
            p2 = self.catboost.predict(X)
            scores = self.meta.predict(np.column_stack([p1, p2]))
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            return

        # çµæœçµåˆ
        result_df = ids.copy()
        result_df['score'] = scores
        # Softmax for Prob
        result_df['prob'] = result_df.groupby('race_id')['score'].transform(lambda x: softmax(x))

        # é€šçŸ¥ãƒ«ãƒ¼ãƒ—
        for race_meta in targets:
            race_id = race_meta['race_id']
            race_df = result_df[result_df['race_id'] == race_id].copy()
            if race_df.empty: continue
            
            # ç‰¹å¾´é‡æŠ½å‡º (for Betting Rules)
            # ã“ã“ã§ãƒ«ãƒ¼ãƒ«åˆ¤å®šç”¨ã®ç‰¹å¾´é‡(score_gap, etc)ã‚’è¨ˆç®—
            race_feats = self._calc_race_features(race_df, race_meta, today_str)

            # é€šçŸ¥
            if not self.dry_run:
                success = self.notifier.send_prediction(race_meta, race_df, race_feats)
                if success: self.notified_races.add(race_id)
                time.sleep(1.0)
            else:
                logger.info(f"[DRY-RUN] {race_meta['title']}")
                print(race_df.sort_values('score', ascending=False).head())
                print("Features:", race_feats)
                print(self.notifier._generate_betting_strategy(race_df, race_feats))

        self._save_state()

    def _calc_race_features(self, df, meta, date_str):
        """ãƒ«ãƒ¼ãƒ«é©ç”¨ã«å¿…è¦ãªç‰¹å¾´é‡ã‚’è¨ˆç®—"""
        sorted_df = df.sort_values('score', ascending=False)
        top_scores = sorted_df['score'].tolist()
        top_odds = sorted_df['odds'].head(3).tolist()
        
        score_gap = top_scores[0] - top_scores[1] if len(top_scores) > 1 else 0
        score_conc = sum(top_scores[:3]) / df['score'].sum() if df['score'].sum() > 0 else 0
        avg_top3 = np.mean(top_odds) if top_odds else 0
        
        venue_code = int(str(meta['race_id'])[4:6])
        
        # surfaceåˆ¤å®š: proc_df(df)ã«surfaceãŒã‚ã‚Œã°ä½¿ã†
        surf = 0
        if 'surface' in df.columns:
            try: surf = int(df['surface'].iloc[0]) - 1 
            except: pass
            if surf < 0: surf = 0

        # distance
        dist = 1600
        if 'distance' in df.columns:
             dist = float(df['distance'].iloc[0])
        elif 'distance' in meta:
             dist = float(meta['distance'])
             
        return {
            'score_gap': score_gap,
            'top1_odds': top_odds[0] if top_odds else 0,
            'avg_top3_odds': avg_top3,
            'score_conc': score_conc,
            'n_horses': len(df),
            'distance': dist,
            'surface': surf,
            'venue': venue_code - 1,
            'month': datetime.strptime(date_str, '%Y%m%d').month
        }

def main():
    parser = argparse.ArgumentParser(description='Automated Prediction & Notification (v23)')
    parser.add_argument('--dry-run', action='store_true', help='é€šçŸ¥ã‚’é€ä¿¡ã›ãšã«å®Ÿè¡Œ')
    parser.add_argument('--date', type=str, help='å¯¾è±¡æ—¥ä»˜ (YYYYMMDD or YYYY-MM-DD)')
    args = parser.parse_args()
    
    target_date = args.date
    if target_date and '-' in target_date:
        # YYYY-MM-DD -> YYYYMMDD (load_race_list expects YYYYMMDD?)
        # Actually logic inside run() handles replacement.
        # But let's standardize to YYYY-MM-DD for consistency
        pass

    predictor = AutoPredictor(dry_run=args.dry_run, target_date=target_date)
    predictor.run()

if __name__ == "__main__":
    main()
