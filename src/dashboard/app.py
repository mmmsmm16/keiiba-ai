import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import matplotlib.pyplot as plt

# „Éö„Éº„Ç∏Ë®≠ÂÆö
st.set_page_config(
    page_title="ÊúÄÂº∑AI „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ",
    layout="wide"
)

st.title("üèá ÊúÄÂº∑Á´∂È¶¨AI: ÂàÜÊûê„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ")

# „Éá„Ç£„É¨„ÇØ„Éà„É™Ë®≠ÂÆö
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.join(BASE_DIR, '../../')
EXPERIMENTS_DIR = os.path.join(PROJECT_ROOT, 'experiments')
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')

# „Çø„Éñ‰ΩúÊàê
tab1, tab2, tab3, tab4 = st.tabs(["Ê¶ÇË¶Å (Overview)", "ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ (Feature Importance)", "„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ (ROI)", "‰∫àÊ∏¨ÂÆüË°å (Predict)"])

with tab1:
    st.header("ÂÆüÈ®ìÂ±•Ê≠¥ (Experiment History)")
    
    history_path = os.path.join(EXPERIMENTS_DIR, 'history.csv')
    if os.path.exists(history_path):
        df_history = pd.read_csv(history_path)
        st.dataframe(df_history)
        
        # „É°„Éà„É™„ÇØ„Çπ„ÅÆÊé®Áßª„Éó„É≠„ÉÉ„Éà
        st.subheader("Á≤æÂ∫¶„É°„Éà„É™„ÇØ„Çπ„ÅÆÊé®Áßª")
        if not df_history.empty:
            metric = st.selectbox("ÊåáÊ®ô„ÇíÈÅ∏Êäû", ["rmse", "ndcg", "map@10"], index=1)
            if metric in df_history.columns:
                st.line_chart(df_history.set_index('timestamp')[metric])
            else:
                st.warning(f"ÊåáÊ®ô '{metric}' „ÅåÂ±•Ê≠¥„Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
    else:
        st.warning("ÂÆüÈ®ìÂ±•Ê≠¥„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Åæ„Åö„ÅØÂ≠¶Áøí(train.py)„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

with tab2:
    st.header("ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ (Feature Importance)")
    
    # Á∞°ÊòìÁöÑ„Å´TabNet„ÅÆ‰øùÂ≠òÊ∏à„ÅøÁîªÂÉè„ÇíË°®Á§∫
    tabnet_imp_path = os.path.join(MODELS_DIR, 'tabnet_importance.png')
    if os.path.exists(tabnet_imp_path):
        st.image(tabnet_imp_path, caption="TabNet ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶")
    else:
        st.info("TabNet„ÅÆÈáçË¶ÅÂ∫¶„Éó„É≠„ÉÉ„ÉàÁîªÂÉè„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")

with tab3:
    st.header("ÂõûÂèéÁéá„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ (ROI Simulation)")
    
    sim_path = os.path.join(EXPERIMENTS_DIR, 'latest_simulation.json')
    if os.path.exists(sim_path):
        with open(sim_path, 'r') as f:
            sim_data = json.load(f)
            
        st.markdown(f"**ÊúÄÁµÇÊõ¥Êñ∞:** {sim_data.get('timestamp')}")
        
        # 1. Êà¶Áï•Âà•„Çµ„Éû„É™
        st.subheader("Êà¶Áï•Âà•„Çµ„Éû„É™ (ÂçòÁ¥î1ÁÇπË≤∑„ÅÑ)")
        strat = sim_data.get('strategies', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ÊúÄÂ§ßÊúüÂæÖÂÄ§ (Max EV)")
            max_ev = strat.get('max_ev', {})
            st.metric("ÂõûÂèéÁéá (ROI)", f"{max_ev.get('roi', 0):.2f}%")
            st.metric("ÁöÑ‰∏≠Áéá (Hit)", f"{max_ev.get('accuracy', 0):.2%}")
            
        with col2:
            st.markdown("### ÊúÄÂ§ß„Çπ„Ç≥„Ç¢ (Max Score)")
            max_score = strat.get('max_score', {})
            st.metric("ÂõûÂèéÁéá (ROI)", f"{max_score.get('roi', 0):.2f}%")
            st.metric("ÁöÑ‰∏≠Áéá (Hit)", f"{max_score.get('accuracy', 0):.2%}")

        # 2. ROI Curve
        st.subheader("ÂõûÂèéÁéá„Ç´„Éº„Éñ (ÊúüÂæÖÂÄ§ÈñæÂÄ§„Åî„Å®„ÅÆÊé®Áßª)")
        st.markdown("ÊúüÂæÖÂÄ§„Åå **ÈñæÂÄ§** „ÇíË∂Ö„Åà„ÅüÈ¶¨„ÇíÂçòÂãùË≥ºÂÖ•„Åó„ÅüÂ†¥Âêà„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥")
        curve_data = sim_data.get('roi_curve', [])
        
        if curve_data:
            df_curve = pd.DataFrame(curve_data)
            
            # „Ç∞„É©„ÉïÊèèÁîª
            fig, ax1 = plt.subplots(figsize=(10, 6))
            
            ax1.set_xlabel('ÊúüÂæÖÂÄ§ÈñæÂÄ§ (Expected Value Threshold)')
            ax1.set_ylabel('ÂõûÂèéÁéá (%)', color='tab:blue')
            ax1.plot(df_curve['threshold'], df_curve['roi'], color='tab:blue', marker='o', label='ÂõûÂèéÁéá', linestyle='-', linewidth=2)
            ax1.tick_params(axis='y', labelcolor='tab:blue')
            ax1.axhline(100, color='red', linestyle='--', alpha=0.7, label='ÊêçÁõäÂàÜÂ≤ê (100%)') # 100%„É©„Ç§„É≥
            
            ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
            ax2.set_ylabel('Ë≥ºÂÖ•‰ª∂Êï∞ (Bet Count)', color='tab:orange')
            ax2.bar(df_curve['threshold'], df_curve['bet_count'], color='tab:orange', alpha=0.3, width=0.05, label='Ë≥ºÂÖ•‰ª∂Êï∞')
            ax2.tick_params(axis='y', labelcolor='tab:orange')
            
            # Âá°‰æã
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

            st.pyplot(fig)
            st.dataframe(df_curve)
        else:
            st.warning("„Ç´„Éº„Éñ„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")

        # 3. Complex Betting
        st.subheader("Ë§áÂêàÈ¶¨Âà∏„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ (Box 5)")
        st.markdown("„Çπ„Ç≥„Ç¢‰∏ä‰Ωç5È†≠„ÇíBOXË≤∑„ÅÑ„Åó„ÅüÂ†¥Âêà„ÅÆÂõûÂèéÁéá„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥")
        
        strategies = sim_data.get('strategies', {})
        complex_keys = ['umaren_box5', 'sanrenpuku_box5', 'sanrentan_box5']
        
        complex_data = []
        names = {
            'umaren_box5': 'È¶¨ÈÄ£ Box5 (10ÁÇπ)', 
            'sanrenpuku_box5': '3ÈÄ£Ë§á Box5 (10ÁÇπ)', 
            'sanrentan_box5': '3ÈÄ£Âçò Box5 (60ÁÇπ)'
        }
        
        for k in complex_keys:
            if k in strategies:
                d = strategies[k]
                complex_data.append({
                    'Âà∏Á®Æ (Strategy)': names.get(k, k),
                    'ÂõûÂèéÁéá (ROI)': f"{d['roi']:.2f}%",
                    'ÁöÑ‰∏≠Áéá (Hit Rate)': f"{d['accuracy']*100:.2f}%",
                    'Á∑èÊäïË≥áÈ°ç': f"{d['bet']:,}ÂÜÜ",
                    'ÊâïÊàªÁ∑èÈ°ç': f"{d['return']:,}ÂÜÜ",
                    'ÂØæË±°„É¨„Éº„ÇπÊï∞': d['races']
                })
        
        if complex_data:
            st.table(pd.DataFrame(complex_data))
        else:
            st.info("Ë§áÂêàÈ¶¨Âà∏„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÁµêÊûú„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ")
    else:
        st.warning("„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÁµêÊûú„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇÂÖà„Å´ 'src/model/evaluate.py' „ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

# --------------------------------------------------------------------------------
# Tab 4: ‰∫àÊ∏¨ÂÆüË°å (Real-time Prediction)
# --------------------------------------------------------------------------------
with tab4:
    st.header("‰∫àÊ∏¨ÂÆüË°å (Real-time Prediction)")
    st.markdown("ÊåáÂÆö„Åó„ÅüÊó•‰ªò„Éª„É¨„Éº„Çπ„ÅÆ‰∫àÊ∏¨„Çí„É™„Ç¢„É´„Çø„Ç§„É†„Å´ÂÆüË°å„Åó„Åæ„Åô„ÄÇ„Éá„Éº„Çø„ÅØPC-KEIBA DB„Åã„ÇâÂèñÂæó„Åó„Åæ„Åô„ÄÇ")

    # ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Éù„Éº„Éà („Åì„Åì„Åß„Ç§„É≥„Éù„Éº„Éà„Åó„Å¶„Çπ„Ç≥„Éº„Éó„ÇíÈôêÂÆö)
    import sys
    sys.path.append(os.path.join(BASE_DIR, '../'))
    from inference.loader import InferenceDataLoader
    from inference.preprocessor import InferencePreprocessor
    from model.ensemble import EnsembleModel
    from scipy.special import softmax

    # „Ç≠„É£„ÉÉ„Ç∑„É•„Åï„Çå„Åü„É¢„Éá„É´„Å®„Éó„É™„Éó„É≠„Çª„ÉÉ„Çµ„ÅÆ„É≠„Éº„ÉâÈñ¢Êï∞
    @st.cache_resource
    def load_model_resources():
        model_path = os.path.join(MODELS_DIR, 'ensemble_model.pkl')
        if not os.path.exists(model_path):
            return None
        model = EnsembleModel()
        model.load_model(model_path)
        return model

    @st.cache_resource
    def load_preprocessor_resources():
        # Preprocessor„ÅØÈÅéÂéª„Éá„Éº„Çø„Çí„É≠„Éº„Éâ„Åô„Çã„Åü„ÇÅÈáç„ÅÑ„ÄÇ„Ç≠„É£„ÉÉ„Ç∑„É•„Åô„Çã„ÄÇ
        preprocessor = InferencePreprocessor()
        # „ÉÄ„Éü„ÉºÂÆüË°å„Åß„Éá„Éº„Çø„Çí„É≠„Éº„Éâ„Åï„Åõ„ÇãÔºàInferencePreprocessor„ÅÆË®≠Ë®àÊ¨°Á¨¨„Å†„Åå„ÄÅ
        # preprocessÂàùÂõûÂëº„Å≥Âá∫„ÅóÊôÇ„Å´„É≠„Éº„Éâ„Åï„Çå„Çã„Å™„Çâ„ÄÅ„Åì„Åì„ÅßÊòéÁ§∫ÁöÑ„Å´Âëº„Å≥Âá∫„Åô„Åã„ÄÅ
        # „Ç§„É≥„Çπ„Çø„É≥„Çπ„Çí„Ç≠„É£„ÉÉ„Ç∑„É•„Åó„Å¶‰Ωø„ÅÑÂõû„ÅôÔºâ
        # constructor„Åß„ÅØ„É≠„Éº„Éâ„Åó„Å™„ÅÑÂÆüË£Ö„Å†„Å£„Åü„Åü„ÇÅ„ÄÅpreprocess„É°„ÇΩ„ÉÉ„ÉâÂÜÖ„Åß„É≠„Éº„Éâ„Åï„Çå„Çã„ÄÇ
        # „Éá„Éº„Çø„Éï„É¨„Éº„É†Ëá™‰Ωì„Çí„Ç≠„É£„ÉÉ„Ç∑„É•„Åô„ÇãË®≠Ë®à„Å´Â§âÊõ¥„Åó„Å™„ÅÑ„Å®ÊØéÂõû„É≠„Éº„Éâ„Åï„Çå„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„ÄÇ
        # src/inference/preprocessor.py „ÇíË¶ã„Çã„Å®„ÄÅpreprocess() ÂÜÖ„Åß pd.read_parquet „Åó„Å¶„ÅÑ„Çã„ÄÇ
        # „Åì„Çå„ÇíÂõûÈÅø„Åô„Çã„Å´„ÅØ preprocessor Ëá™‰Ωì„Å´„Éá„Éº„Çø„Çí‰øùÊåÅ„Åï„Åõ„Çã„Åã„ÄÅ„Éá„Éº„Çø„É≠„Éº„ÉâÈñ¢Êï∞„ÇíÂàÜ„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ
        # „Åì„Åì„Åß„ÅØÁ∞°ÊòìÁöÑ„Å´„ÄÅpreprocessor„Ç§„É≥„Çπ„Çø„É≥„Çπ„Çí„Ç≠„É£„ÉÉ„Ç∑„É•„Åô„ÇãÔºà„Åü„Å†„ÅóparquetË™≠„ÅøËæº„Åø„ÅØ„Ç≠„É£„ÉÉ„Ç∑„É•„Åï„Çå„Å™„ÅÑ„Åã„ÇÇÔºâ„ÄÇ
        # „Éá„Éº„Çø„É≠„Éº„ÉâÈÉ®ÂàÜ„Å†„Åë„Ç≠„É£„ÉÉ„Ç∑„É•Èñ¢Êï∞„Å´„Åô„Çã„ÅÆ„Åå„Éô„Çπ„Éà„ÄÇ
        return preprocessor

    # Data Loader for historical data (Heavy)
    @st.cache_resource
    def get_historical_data():
        data_path = os.path.join(PROJECT_ROOT, 'data/processed/preprocessed_data.parquet')
        if os.path.exists(data_path):
            st.info("Loading historical data to memory (One-time operation)...")
            return pd.read_parquet(data_path)
        return None

    # UI Inputs
    col_in1, col_in2, col_in3 = st.columns(3)
    with col_in1:
        selected_date = st.date_input(
            "ÈñãÂÇ¨Êó•",
            value=pd.Timestamp.now(),
            min_value=pd.Timestamp('2020-01-01'),
            max_value=pd.Timestamp.now() + pd.Timedelta(days=30)
        )
        target_date = selected_date.strftime('%Y%m%d')
    with col_in2:
        venue_map = {
            '01': 'Êú≠Âπå', '02': 'ÂáΩÈ§®', '03': 'Á¶èÂ≥∂', '04': 'Êñ∞ÊΩü', '05': 'Êù±‰∫¨', 
            '06': '‰∏≠Â±±', '07': '‰∏≠‰∫¨', '08': '‰∫¨ÈÉΩ', '09': 'Èò™Á•û', '10': 'Â∞èÂÄâ'
        }
        venue_code = st.selectbox("ÈñãÂÇ¨Â†¥ÊâÄ", options=list(venue_map.keys()), format_func=lambda x: f"{x}: {venue_map[x]}")
    with col_in3:
        race_no = st.number_input("„É¨„Éº„ÇπÁï™Âè∑", min_value=1, max_value=12, value=11)

    # Race ID (Check purpose only, not used for querying)
    # PC-KEIBA DB Key is (Year, Venue, Kai, Nichime, Race), not (Date, Venue, Race).
    # So we load by Date and filter in memory.
    st.info(f"Target: {target_date} / {venue_map.get(venue_code)} / {race_no}R")

    if st.button("‰∫àÊ∏¨ÂÆüË°å (Predict)"):
        with st.spinner('„É¢„Éá„É´„Å®„Éá„Éº„Çø„ÇíÊ∫ñÂÇô‰∏≠...'):
            model = load_model_resources()
            hist_df = get_historical_data() # Cached load
            
            if model is None:
                st.error("„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì (models/ensemble_model.pkl)")
            elif hist_df is None:
                st.error("ÈÅéÂéª„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì (data/processed/preprocessed_data.parquet)")
            else:
                # 1. „Éá„Éº„Çø„É≠„Éº„Éâ
                loader = InferenceDataLoader()
                try:
                    # Load all races for the date then filter
                    new_df = loader.load(target_date=target_date)
                except Exception as e:
                    new_df = pd.DataFrame()
                    st.error(f"„Éá„Éº„Çø„É≠„Éº„Éâ„Ç®„É©„Éº: {e}")

                # Filter by Venue and Race No
                if not new_df.empty:
                    # Ensure types match for filtering
                    # new_df['venue'] is code string '05', venue_code is '05'
                    # new_df['race_number'] is int, race_no is int
                    new_df = new_df[
                        (new_df['venue'] == venue_code) & 
                        (new_df['race_number'] == race_no)
                    ]

                if new_df.empty:
                    st.warning(f"„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü (Date: {target_date}, Venue: {venue_code}, Race: {race_no})„ÄÇPC-KEIBA„Åß„Éá„Éº„ÇøÁôªÈå≤Ê∏à„Åø„ÅãÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
                else:
                    st.success(f"„Éá„Éº„Çø„É≠„Éº„ÉâÊàêÂäü: {len(new_df)} È†≠")
                    
                    # 2. ÂâçÂá¶ÁêÜ
                    # „Éí„Çπ„Éà„É™„Ç´„É´„Éá„Éº„Çø„ÅÆ„É≠„Éº„Éâ„ÇíÈ´òÈÄüÂåñ„Åô„Çã„Åü„ÇÅ„Å´„Ç≠„É£„ÉÉ„Ç∑„É•Âà©Áî®
                    preprocessor = InferencePreprocessor()
                    
                    try:
                        # ‰øÆÊ≠£: „Ç≠„É£„ÉÉ„Ç∑„É•„Åó„Åühistory_df„ÇíÊ∏°„Åô
                        X, ids = preprocessor.preprocess(new_df, history_df=hist_df)
                        
                        if X.empty:
                            st.error("ÂâçÂá¶ÁêÜÂæå„ÅÆÁâπÂæ¥Èáè„ÅåÁîüÊàê„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
                        else:
                            # „É¨„Éº„ÇπÊÉÖÂ†±„Ç´„Éº„Éâ„ÅÆË°®Á§∫
                            race_info = new_df.iloc[0]
                            
                            # „Éû„ÉÉ„Éî„É≥„Ç∞ËæûÊõ∏
                            surface_map = {'10': 'Ëäù', '11': 'Ëäù„ÉªÁõ¥Á∑ö', '20': '„ÉÄ„Éº„Éà', '21': '„ÉÄ„Éº„Éà„ÉªÁõ¥Á∑ö', '30': 'ÈöúÂÆ≥„ÉªËäù', '31': 'ÈöúÂÆ≥„ÉªËäùÁõ¥Á∑ö'}
                            state_map = {'1': 'ËâØ', '2': 'Á®çÈáç', '3': 'Èáç', '4': '‰∏çËâØ'}
                            weather_map = {'1': 'Êô¥', '2': 'Êõá', '3': 'Èõ®', '4': 'Â∞èÈõ®', '5': 'Â∞èÈõ™', '6': 'Èõ™'}
                            
                            st.markdown("---")
                            st.subheader(f"üìã „É¨„Éº„ÇπÊÉÖÂ†±")
                            
                            info_col1, info_col2, info_col3 = st.columns(3)
                            with info_col1:
                                st.metric("„É¨„Éº„ÇπÂêç", race_info.get('title', 'N/A'))
                                st.metric("Ë∑ùÈõ¢", f"{race_info.get('distance', 'N/A')}m")
                            with info_col2:
                                surf = surface_map.get(str(race_info.get('surface', '')), 'N/A')
                                st.metric("È¶¨Â†¥", surf)
                                state = state_map.get(str(race_info.get('state', '')), 'N/A')
                                st.metric("È¶¨Â†¥Áä∂ÊÖã", state)
                            with info_col3:
                                weather = weather_map.get(str(race_info.get('weather', '')), 'N/A')
                                st.metric("Â§©ÂÄô", weather)
                                st.metric("Âá∫Ëµ∞È†≠Êï∞", f"{len(new_df)}È†≠")
                            
                            st.markdown("---")
                            
                            # 3. ‰∫àÊ∏¨
                            preds = model.predict(X)
                            
                            # ÁµêÊûúÊï¥ÂΩ¢
                            results = ids.copy()
                            results['score'] = preds
                            results['prob'] = results.groupby('race_id')['score'].transform(lambda x: softmax(x))
                            
                            # ÊúüÂæÖÂÄ§Ë®àÁÆó
                            results['expected_value'] = results['prob'] * results['odds']
                            results['recommended'] = results['expected_value'] > 1.0
                            
                            # Ë°®Á§∫Áî®„Ç´„É©„É†
                            results['pred_rank'] = results.groupby('race_id')['score'].rank(ascending=False, method='min')
                            
                            # Ë©≥Á¥∞ÊÉÖÂ†±„ÇíË°®Á§∫
                            display_cols = ['pred_rank', 'horse_number', 'horse_name', 'score', 'prob', 'odds', 'popularity', 'expected_value']
                            display_df = results.sort_values('pred_rank')[display_cols]
                            
                            # „Ç´„É©„É†ÂêçÊó•Êú¨Ë™ûÂåñ
                            rename_map = {
                                'pred_rank': '‰∫àÊÉ≥È†Ü‰Ωç',
                                'horse_number': 'È¶¨Áï™',
                                'horse_name': 'È¶¨Âêç',
                                'score': '‰∫àÊ∏¨„Çπ„Ç≥„Ç¢',
                                'prob': 'AIÂãùÁéá',
                                'odds': 'ÂçòÂãù„Ç™„ÉÉ„Ç∫',
                                'popularity': '‰∫∫Ê∞ó',
                                'expected_value': 'ÊúüÂæÖÂÄ§'
                            }
                            display_df = display_df.rename(columns=rename_map)
                            
                            # Ëâ≤‰ªò„Åë„Å®„Éè„Ç§„É©„Ç§„Éà
                            st.subheader(f"üéØ ‰∫àÊ∏¨ÁµêÊûú: {venue_map.get(venue_code, venue_code)} {race_no}R")
                            
                            # „Åä„Åô„Åô„ÇÅÈ¶¨„ÅÆÊï∞„ÇíË°®Á§∫
                            rec_count = results['recommended'].sum()
                            if rec_count > 0:
                                st.info(f"üí° ÊúüÂæÖÂÄ§„Åå1.0„ÇíË∂Ö„Åà„Çã„Äå„Åä„Åô„Åô„ÇÅÈ¶¨„Äç„Åå {rec_count} È†≠„ÅÑ„Åæ„ÅôÔºàÈªÑËâ≤„ÉªËµ§Ëâ≤„Åß„Éè„Ç§„É©„Ç§„ÉàÔºâ")
                            
                            def highlight_rows(s):
                                rank = s['‰∫àÊÉ≥È†Ü‰Ωç']
                                exp_val = s.get('ÊúüÂæÖÂÄ§', 0)
                                is_rec = exp_val > 1.0
                                
                                # „Çà„ÇäÊ∑°„ÅÑËâ≤„ÅßË¶ã„ÇÑ„Åô„Åè
                                if is_rec and rank == 1:
                                    return ['background-color: #ffb3ba; color: black'] * len(s)  # „É©„Ç§„Éà„Éî„É≥„ÇØ
                                elif is_rec:
                                    return ['background-color: #ffffba; color: black'] * len(s)  # „É©„Ç§„Éà„Ç§„Ç®„É≠„Éº
                                elif rank == 1:
                                    return ['background-color: #ffe6e6; color: black'] * len(s)  # Ê•µËñÑ„Éî„É≥„ÇØ
                                elif rank <= 3:
                                    return ['background-color: #f5f5f5; color: black'] * len(s)  # ËñÑ„Ç∞„É¨„Éº
                                else:
                                    return [''] * len(s)

                            # style.apply „ÅØ axis=1 „ÅßË°å„Åî„Å®„Å´ÈÅ©Áî®
                            st.dataframe(
                                display_df.style.apply(highlight_rows, axis=1).format({
                                    '‰∫àÊ∏¨„Çπ„Ç≥„Ç¢': '{:.4f}', 
                                    'AIÂãùÁéá': '{:.2%}',
                                    'ÊúüÂæÖÂÄ§': '{:.2f}'
                                })
                            )

                    except Exception as e:
                        st.error(f"‰∫àÊ∏¨ÂÆüË°å‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}")
