import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import matplotlib.pyplot as plt

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æœ€å¼·AI ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    layout="wide"
)

st.title("ğŸ‡ æœ€å¼·ç«¶é¦¬AI: åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.join(BASE_DIR, '../../')
EXPERIMENTS_DIR = os.path.join(PROJECT_ROOT, 'experiments')
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')

# ã‚¿ãƒ–ä½œæˆ
tab1, tab2, tab3, tab4 = st.tabs(["æ¦‚è¦ (Overview)", "ç‰¹å¾´é‡é‡è¦åº¦ (Feature Importance)", "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ROI)", "äºˆæ¸¬å®Ÿè¡Œ (Predict)"])

with tab1:
    st.header("å®Ÿé¨“å±¥æ­´ (Experiment History)")
    
    history_path = os.path.join(EXPERIMENTS_DIR, 'history.csv')
    if os.path.exists(history_path):
        df_history = pd.read_csv(history_path)
        st.dataframe(df_history)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¨ç§»ãƒ—ãƒ­ãƒƒãƒˆ
        st.subheader("ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¨ç§»")
        if not df_history.empty:
            metric = st.selectbox("æŒ‡æ¨™ã‚’é¸æŠ", ["rmse", "ndcg", "map@10"], index=1)
            if metric in df_history.columns:
                st.line_chart(df_history.set_index('timestamp')[metric])
            else:
                st.warning(f"æŒ‡æ¨™ '{metric}' ãŒå±¥æ­´ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.warning("å®Ÿé¨“å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãšã¯å­¦ç¿’(train.py)ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

with tab2:
    st.header("ç‰¹å¾´é‡é‡è¦åº¦ (Feature Importance)")
    
    # ç°¡æ˜“çš„ã«TabNetã®ä¿å­˜æ¸ˆã¿ç”»åƒã‚’è¡¨ç¤º
    tabnet_imp_path = os.path.join(MODELS_DIR, 'tabnet_importance.png')
    if os.path.exists(tabnet_imp_path):
        st.image(tabnet_imp_path, caption="TabNet ç‰¹å¾´é‡é‡è¦åº¦")
    else:
        st.info("TabNetã®é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

with tab3:
    st.header("å›åç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ROI Simulation)")
    
    sim_path = os.path.join(EXPERIMENTS_DIR, 'latest_simulation.json')
    if os.path.exists(sim_path):
        with open(sim_path, 'r') as f:
            sim_data = json.load(f)
            
        st.markdown(f"**æœ€çµ‚æ›´æ–°:** {sim_data.get('timestamp')}")
        
        # 1. æˆ¦ç•¥åˆ¥ã‚µãƒãƒª
        st.subheader("æˆ¦ç•¥åˆ¥ã‚µãƒãƒª (å˜ç´”1ç‚¹è²·ã„)")
        strat = sim_data.get('strategies', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### æœ€å¤§æœŸå¾…å€¤ (Max EV)")
            max_ev = strat.get('max_ev', {})
            st.metric("å›åç‡ (ROI)", f"{max_ev.get('roi', 0):.2f}%")
            st.metric("çš„ä¸­ç‡ (Hit)", f"{max_ev.get('accuracy', 0):.2%}")
            
        with col2:
            st.markdown("### æœ€å¤§ã‚¹ã‚³ã‚¢ (Max Score)")
            max_score = strat.get('max_score', {})
            st.metric("å›åç‡ (ROI)", f"{max_score.get('roi', 0):.2f}%")
            st.metric("çš„ä¸­ç‡ (Hit)", f"{max_score.get('accuracy', 0):.2%}")

        # 2. ROI Curve
        st.subheader("å›åç‡ã‚«ãƒ¼ãƒ– (æœŸå¾…å€¤é–¾å€¤ã”ã¨ã®æ¨ç§»)")
        st.markdown("æœŸå¾…å€¤ãŒ **é–¾å€¤** ã‚’è¶…ãˆãŸé¦¬ã‚’å˜å‹è³¼å…¥ã—ãŸå ´åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        curve_data = sim_data.get('roi_curve', [])
        
        if curve_data:
            df_curve = pd.DataFrame(curve_data)
            
            # ã‚°ãƒ©ãƒ•æç”»
            fig, ax1 = plt.subplots(figsize=(10, 6))
            
            ax1.set_xlabel('æœŸå¾…å€¤é–¾å€¤ (Expected Value Threshold)')
            ax1.set_ylabel('å›åç‡ (%)', color='tab:blue')
            ax1.plot(df_curve['threshold'], df_curve['roi'], color='tab:blue', marker='o', label='å›åç‡', linestyle='-', linewidth=2)
            ax1.tick_params(axis='y', labelcolor='tab:blue')
            ax1.axhline(100, color='red', linestyle='--', alpha=0.7, label='æç›Šåˆ†å² (100%)') # 100%ãƒ©ã‚¤ãƒ³
            
            ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
            ax2.set_ylabel('è³¼å…¥ä»¶æ•° (Bet Count)', color='tab:orange')
            ax2.bar(df_curve['threshold'], df_curve['bet_count'], color='tab:orange', alpha=0.3, width=0.05, label='è³¼å…¥ä»¶æ•°')
            ax2.tick_params(axis='y', labelcolor='tab:orange')
            
            # å‡¡ä¾‹
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

            st.pyplot(fig)
            st.dataframe(df_curve)
        else:
            st.warning("ã‚«ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.warning("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« 'src/model/evaluate.py' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# --------------------------------------------------------------------------------
# Tab 4: äºˆæ¸¬å®Ÿè¡Œ (Real-time Prediction)
# --------------------------------------------------------------------------------
with tab4:
    st.header("äºˆæ¸¬å®Ÿè¡Œ (Real-time Prediction)")
    st.markdown("æŒ‡å®šã—ãŸæ—¥ä»˜ãƒ»ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å®Ÿè¡Œã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯PC-KEIBA DBã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚")

    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (ã“ã“ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ã‚¹ã‚³ãƒ¼ãƒ—ã‚’é™å®š)
    import sys
    sys.path.append(os.path.join(BASE_DIR, '../'))
    from inference.loader import InferenceDataLoader
    from inference.preprocessor import InferencePreprocessor
    from model.ensemble import EnsembleModel
    from scipy.special import softmax

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰é–¢æ•°
    @st.cache_resource
    def load_model_resources():
        model_path = os.path.join(MODELS_DIR, 'ensemble_model.pkl')
        if not os.path.exists(model_path):
            return None
        model = EnsembleModel()
        model.load_model(model_path)
        return model

    @st.cache_resource
    def load_preprocessor_resources():
        # Preprocessorã¯éå»ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚é‡ã„ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã€‚
        preprocessor = InferencePreprocessor()
        # ãƒ€ãƒŸãƒ¼å®Ÿè¡Œã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã•ã›ã‚‹ï¼ˆInferencePreprocessorã®è¨­è¨ˆæ¬¡ç¬¬ã ãŒã€
        # preprocessåˆå›å‘¼ã³å‡ºã—æ™‚ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ãªã‚‰ã€ã“ã“ã§æ˜ç¤ºçš„ã«å‘¼ã³å‡ºã™ã‹ã€
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ä½¿ã„å›ã™ï¼‰
        # constructorã§ã¯ãƒ­ãƒ¼ãƒ‰ã—ãªã„å®Ÿè£…ã ã£ãŸãŸã‚ã€preprocessãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã€‚
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è‡ªä½“ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹è¨­è¨ˆã«å¤‰æ›´ã—ãªã„ã¨æ¯å›ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
        # src/inference/preprocessor.py ã‚’è¦‹ã‚‹ã¨ã€preprocess() å†…ã§ pd.read_parquet ã—ã¦ã„ã‚‹ã€‚
        # ã“ã‚Œã‚’å›é¿ã™ã‚‹ã«ã¯ preprocessor è‡ªä½“ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã•ã›ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•°ã‚’åˆ†ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã€preprocessorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ï¼ˆãŸã ã—parquetèª­ã¿è¾¼ã¿ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œãªã„ã‹ã‚‚ï¼‰ã€‚
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰éƒ¨åˆ†ã ã‘ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°ã«ã™ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã€‚
        return preprocessor

    # Data Loader for historical data (Heavy)
    @st.cache_resource
    def get_historical_data():
        data_path = os.path.join(PROJECT_ROOT, 'data/processed/preprocessed_data.parquet')
        if os.path.exists(data_path):
            st.info("Loading historical data to memory (One-time operation)...")
            return pd.read_parquet(data_path)
        return None

    # UI Inputs
    col_in1, col_in2, col_in3 = st.columns(3)
    with col_in1:
        target_date = st.text_input("é–‹å‚¬æ—¥ (YYYYMMDD)", value=pd.Timestamp.now().strftime('%Y%m%d'))
    with col_in2:
        venue_map = {
            '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ', '05': 'æ±äº¬', 
            '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½', '09': 'é˜ªç¥', '10': 'å°å€‰'
        }
        venue_code = st.selectbox("é–‹å‚¬å ´æ‰€", options=list(venue_map.keys()), format_func=lambda x: f"{x}: {venue_map[x]}")
    with col_in3:
        race_no = st.number_input("ãƒ¬ãƒ¼ã‚¹ç•ªå·", min_value=1, max_value=12, value=11)

    # Race ID (Check purpose only, not used for querying)
    # PC-KEIBA DB Key is (Year, Venue, Kai, Nichime, Race), not (Date, Venue, Race).
    # So we load by Date and filter in memory.
    st.info(f"Target: {target_date} / {venue_map.get(venue_code)} / {race_no}R")

    if st.button("äºˆæ¸¬å®Ÿè¡Œ (Predict)"):
        with st.spinner('ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...'):
            model = load_model_resources()
            hist_df = get_historical_data() # Cached load
            
            if model is None:
                st.error("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (models/ensemble_model.pkl)")
            elif hist_df is None:
                st.error("éå»ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (data/processed/preprocessed_data.parquet)")
            else:
                # 1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
                loader = InferenceDataLoader()
                try:
                    # Load all races for the date then filter
                    new_df = loader.load(target_date=target_date)
                except Exception as e:
                    new_df = pd.DataFrame()
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

                # Filter by Venue and Race No
                if not new_df.empty:
                    # Ensure types match for filtering
                    # new_df['venue'] is code string '05', venue_code is '05'
                    # new_df['race_number'] is int, race_no is int
                    new_df = new_df[
                        (new_df['venue'] == venue_code) & 
                        (new_df['race_number'] == race_no)
                    ]

                if new_df.empty:
                    st.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (Date: {target_date}, Venue: {venue_code}, Race: {race_no})ã€‚PC-KEIBAã§ãƒ‡ãƒ¼ã‚¿ç™»éŒ²æ¸ˆã¿ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.success(f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {len(new_df)} é ­")
                    
                    # 2. å‰å‡¦ç†
                    # ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨
                    preprocessor = InferencePreprocessor()
                    
                    try:
                        # ä¿®æ­£: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãŸhistory_dfã‚’æ¸¡ã™
                        X, ids = preprocessor.preprocess(new_df, history_df=hist_df)
                        
                        if X.empty:
                            st.error("å‰å‡¦ç†å¾Œã®ç‰¹å¾´é‡ãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                        else:
                            # 3. äºˆæ¸¬
                            preds = model.predict(X)
                            
                            # çµæœæ•´å½¢
                            results = ids.copy()
                            results['score'] = preds
                            results['prob'] = results.groupby('race_id')['score'].transform(lambda x: softmax(x))
                            
                            # è¡¨ç¤ºç”¨ã‚«ãƒ©ãƒ 
                            results['pred_rank'] = results.groupby('race_id')['score'].rank(ascending=False, method='min')
                            # results['horse_name'] ã¯ ids ã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ä¸Šæ›¸ãä¸è¦ (indexä¸ä¸€è‡´ã§NaNã«ãªã‚‹ã®ã‚’é˜²ã)
                            
                            # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
                            display_cols = ['pred_rank', 'horse_number', 'horse_name', 'score', 'prob', 'odds', 'popularity']
                            display_df = results.sort_values('pred_rank')[display_cols]
                            
                            # ã‚«ãƒ©ãƒ åæ—¥æœ¬èªåŒ–
                            rename_map = {
                                'pred_rank': 'äºˆæƒ³é †ä½',
                                'horse_number': 'é¦¬ç•ª',
                                'horse_name': 'é¦¬å',
                                'score': 'äºˆæ¸¬ã‚¹ã‚³ã‚¢',
                                'prob': 'AIå‹ç‡',
                                'odds': 'å˜å‹ã‚ªãƒƒã‚º',
                                'popularity': 'äººæ°—'
                            }
                            display_df = display_df.rename(columns=rename_map)
                            
                            # è‰²ä»˜ã‘
                            st.subheader(f"äºˆæ¸¬çµæœ: {venue_map.get(venue_code, venue_code)} {race_no}R")
                            
                            def highlight_top(s):
                                # s is a row (Series)
                                # s['äºˆæƒ³é †ä½'] ã‚’å‚ç…§ã™ã‚‹
                                rank = s['äºˆæƒ³é †ä½']
                                if rank == 1:
                                    return ['background-color: #ffcccc; color: black'] * len(s)
                                elif rank <= 3:
                                    return ['background-color: #ffffcc; color: black'] * len(s)
                                else:
                                    return [''] * len(s)

                            # style.apply ã¯ axis=1 ã§è¡Œã”ã¨ã«é©ç”¨
                            st.dataframe(display_df.style.apply(highlight_top, axis=1).format({'äºˆæ¸¬ã‚¹ã‚³ã‚¢': '{:.4f}', 'AIå‹ç‡': '{:.2%}'}))

                    except Exception as e:
                        st.error(f"äºˆæ¸¬å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
