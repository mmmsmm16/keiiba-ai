import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import matplotlib.pyplot as plt
import re
import sys

# „Éö„Éº„Ç∏Ë®≠ÂÆö
st.set_page_config(
    page_title="ÊúÄÂº∑AI „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ",
    layout="wide"
)

st.title("üèá ÊúÄÂº∑Á´∂È¶¨AI: ÂàÜÊûê„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ")

# „Éá„Ç£„É¨„ÇØ„Éà„É™Ë®≠ÂÆö
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.join(BASE_DIR, '../../')
EXPERIMENTS_DIR = os.path.join(PROJECT_ROOT, 'experiments')
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')

# „Çø„Éñ‰ΩúÊàê
tab1, tab2, tab3, tab4 = st.tabs(["Ê¶ÇË¶Å (Overview)", "ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ (Feature Importance)", "„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ (ROI)", "‰∫àÊ∏¨ÂÆüË°å (Predict)"])

with tab1:
    st.header("ÂÆüÈ®ìÂ±•Ê≠¥ (Experiment History)")
    
    history_path = os.path.join(EXPERIMENTS_DIR, 'history.csv')
    if os.path.exists(history_path):
        df_history = pd.read_csv(history_path)
        st.dataframe(df_history)
        
        # „É°„Éà„É™„ÇØ„Çπ„ÅÆÊé®Áßª„Éó„É≠„ÉÉ„Éà
        st.subheader("Á≤æÂ∫¶„É°„Éà„É™„ÇØ„Çπ„ÅÆÊé®Áßª")
        if not df_history.empty:
            metric = st.selectbox("ÊåáÊ®ô„ÇíÈÅ∏Êäû", ["rmse", "ndcg", "map@10"], index=1)
            if metric in df_history.columns:
                st.line_chart(df_history.set_index('timestamp')[metric])
            else:
                st.warning(f"ÊåáÊ®ô '{metric}' „ÅåÂ±•Ê≠¥„Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
    else:
        st.warning("ÂÆüÈ®ìÂ±•Ê≠¥„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Åæ„Åö„ÅØÂ≠¶Áøí(train.py)„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

with tab2:
    st.header("ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ (Feature Importance)")
    
    # Á∞°ÊòìÁöÑ„Å´TabNet„ÅÆ‰øùÂ≠òÊ∏à„ÅøÁîªÂÉè„ÇíË°®Á§∫
    tabnet_imp_path = os.path.join(MODELS_DIR, 'tabnet_importance.png')
    if os.path.exists(tabnet_imp_path):
        st.image(tabnet_imp_path, caption="TabNet ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶")
    else:
        st.info("TabNet„ÅÆÈáçË¶ÅÂ∫¶„Éó„É≠„ÉÉ„ÉàÁîªÂÉè„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")

with tab3:
    st.header("ÂõûÂèéÁéá„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ (ROI Simulation)")
    
    sim_path = os.path.join(EXPERIMENTS_DIR, 'latest_simulation.json')
    if os.path.exists(sim_path):
        with open(sim_path, 'r') as f:
            sim_data = json.load(f)
            
        st.markdown(f"**ÊúÄÁµÇÊõ¥Êñ∞:** {sim_data.get('timestamp')}")
        
        # 1. Êà¶Áï•Âà•„Çµ„Éû„É™
        st.subheader("Êà¶Áï•Âà•„Çµ„Éû„É™ (ÂçòÁ¥î1ÁÇπË≤∑„ÅÑ)")
        strat = sim_data.get('strategies', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ÊúÄÂ§ßÊúüÂæÖÂÄ§ (Max EV)")
            max_ev = strat.get('max_ev', {})
            st.metric("ÂõûÂèéÁéá (ROI)", f"{max_ev.get('roi', 0):.2f}%")
            st.metric("ÁöÑ‰∏≠Áéá (Hit)", f"{max_ev.get('accuracy', 0):.2%}")
            
        with col2:
            st.markdown("### ÊúÄÂ§ß„Çπ„Ç≥„Ç¢ (Max Score)")
            max_score = strat.get('max_score', {})
            st.metric("ÂõûÂèéÁéá (ROI)", f"{max_score.get('roi', 0):.2f}%")
            st.metric("ÁöÑ‰∏≠Áéá (Hit)", f"{max_score.get('accuracy', 0):.2%}")

        # 2. ROI Curve
        st.subheader("ÂõûÂèéÁéá„Ç´„Éº„Éñ (ÊúüÂæÖÂÄ§ÈñæÂÄ§„Åî„Å®„ÅÆÊé®Áßª)")
        st.markdown("ÊúüÂæÖÂÄ§„Åå **ÈñæÂÄ§** „ÇíË∂Ö„Åà„ÅüÈ¶¨„ÇíÂçòÂãùË≥ºÂÖ•„Åó„ÅüÂ†¥Âêà„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥")
        curve_data = sim_data.get('roi_curve', [])
        
        if curve_data:
            df_curve = pd.DataFrame(curve_data)
            
            # „Ç∞„É©„ÉïÊèèÁîª
            fig, ax1 = plt.subplots(figsize=(10, 6))
            
            ax1.set_xlabel('ÊúüÂæÖÂÄ§ÈñæÂÄ§ (Expected Value Threshold)')
            ax1.set_ylabel('ÂõûÂèéÁéá (%)', color='tab:blue')
            ax1.plot(df_curve['threshold'], df_curve['roi'], color='tab:blue', marker='o', label='ÂõûÂèéÁéá', linestyle='-', linewidth=2)
            ax1.tick_params(axis='y', labelcolor='tab:blue')
            ax1.axhline(100, color='red', linestyle='--', alpha=0.7, label='ÊêçÁõäÂàÜÂ≤ê (100%)') # 100%„É©„Ç§„É≥
            
            ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
            ax2.set_ylabel('Ë≥ºÂÖ•‰ª∂Êï∞ (Bet Count)', color='tab:orange')
            ax2.bar(df_curve['threshold'], df_curve['bet_count'], color='tab:orange', alpha=0.3, width=0.05, label='Ë≥ºÂÖ•‰ª∂Êï∞')
            ax2.tick_params(axis='y', labelcolor='tab:orange')
            
            # Âá°‰æã
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

            st.pyplot(fig)
            st.dataframe(df_curve)
        else:
            st.warning("„Ç´„Éº„Éñ„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")

        # 3. Complex Betting
        st.subheader("Ë§áÂêàÈ¶¨Âà∏„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ (Box 5)")
        st.markdown("„Çπ„Ç≥„Ç¢‰∏ä‰Ωç5È†≠„ÇíBOXË≤∑„ÅÑ„Åó„ÅüÂ†¥Âêà„ÅÆÂõûÂèéÁéá„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥")
        
        strategies = sim_data.get('strategies', {})
        complex_keys = ['umaren_box5', 'sanrenpuku_box5', 'sanrentan_box5']
        
        complex_data = []
        names = {
            'umaren_box5': 'È¶¨ÈÄ£ Box5 (10ÁÇπ)', 
            'sanrenpuku_box5': '3ÈÄ£Ë§á Box5 (10ÁÇπ)', 
            'sanrentan_box5': '3ÈÄ£Âçò Box5 (60ÁÇπ)'
        }
        
        for k in complex_keys:
            if k in strategies:
                d = strategies[k]
                complex_data.append({
                    'Âà∏Á®Æ (Strategy)': names.get(k, k),
                    'ÂõûÂèéÁéá (ROI)': f"{d['roi']:.2f}%",
                    'ÁöÑ‰∏≠Áéá (Hit Rate)': f"{d['accuracy']*100:.2f}%",
                    'Á∑èÊäïË≥áÈ°ç': f"{d['bet']:,}ÂÜÜ",
                    'ÊâïÊàªÁ∑èÈ°ç': f"{d['return']:,}ÂÜÜ",
                    'ÂØæË±°„É¨„Éº„ÇπÊï∞': d['races']
                })
        
        if complex_data:
            st.table(pd.DataFrame(complex_data))
        else:
            st.info("Ë§áÂêàÈ¶¨Âà∏„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÁµêÊûú„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ")
    else:
        st.warning("„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÁµêÊûú„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇÂÖà„Å´ 'src/model/evaluate.py' „ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

# --------------------------------------------------------------------------------
# Tab 4: ‰∫àÊ∏¨ÂÆüË°å (Real-time Prediction)
# --------------------------------------------------------------------------------
with tab4:
    st.header("‰∫àÊ∏¨ÂÆüË°å (Real-time Prediction)")
    st.markdown("ÊåáÂÆö„Åó„ÅüÊó•‰ªò„Éª„É¨„Éº„Çπ„ÅÆ‰∫àÊ∏¨„Çí„É™„Ç¢„É´„Çø„Ç§„É†„Å´ÂÆüË°å„Åó„Åæ„Åô„ÄÇ„Éá„Éº„Çø„ÅØPC-KEIBA DB„Åã„ÇâÂèñÂæó„Åó„Åæ„Åô„ÄÇ")

    # ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Éù„Éº„Éà („Åì„Åì„Åß„Ç§„É≥„Éù„Éº„Éà„Åó„Å¶„Çπ„Ç≥„Éº„Éó„ÇíÈôêÂÆö)
    sys.path.append(os.path.join(BASE_DIR, '../'))
    from inference.loader import InferenceDataLoader
    from inference.preprocessor import InferencePreprocessor
    from model.ensemble import EnsembleModel
    from model.lgbm import KeibaLGBM
    from model.catboost_model import KeibaCatBoost
    from model.tabnet_model import KeibaTabNet
    from scipy.special import softmax

    # „É¢„Éá„É´„Éê„Éº„Ç∏„Éß„É≥„ÅÆÂèñÂæó
    def get_model_versions(model_type):
        if not os.path.exists(MODELS_DIR):
            return ['v1']

        files = os.listdir(MODELS_DIR)
        versions = set()

        # Check for legacy/default files
        if model_type == 'ensemble':
            if 'ensemble_model.pkl' in files:
                versions.add('v1')
        else:
            # lgbm.pkl, catboost.pkl, tabnet.pkl/zip
            base_name = f"{model_type}.pkl"
            if model_type == 'tabnet' and 'tabnet.zip' in files:
                versions.add('v1')
            elif base_name in files:
                versions.add('v1')
        
        # Check for versioned files
        prefix = f"{model_type}_"
        for f in files:
            if f.startswith(prefix):
                # Extract tag
                tag = ""
                if f.endswith('.pkl'):
                    tag = f[len(prefix):-4]
                elif f.endswith('.zip') and model_type == 'tabnet':
                    tag = f[len(prefix):-4]
                
                if tag:
                    if model_type == 'ensemble' and tag == 'model':
                        continue # Already handled as v1
                    versions.add(tag)
        
        # Sort versions
        return sorted(list(versions))

    # „Ç≠„É£„ÉÉ„Ç∑„É•„Åï„Çå„Åü„É¢„Éá„É´„Å®„Éó„É™„Éó„É≠„Çª„ÉÉ„Çµ„ÅÆ„É≠„Éº„ÉâÈñ¢Êï∞
    @st.cache_resource
    def load_model_resources(model_type, version):
        model = None
        path = ""
        
        if model_type == 'ensemble':
            model = EnsembleModel()
            # Try specific version first, then default
            path = os.path.join(MODELS_DIR, f'ensemble_{version}.pkl')
            if not os.path.exists(path):
                 path = os.path.join(MODELS_DIR, 'ensemble_model.pkl')
        elif model_type == 'lgbm':
            model = KeibaLGBM()
            path = os.path.join(MODELS_DIR, f'lgbm_{version}.pkl')
            if not os.path.exists(path):
                 path = os.path.join(MODELS_DIR, 'lgbm.pkl')
        elif model_type == 'catboost':
            model = KeibaCatBoost()
            path = os.path.join(MODELS_DIR, f'catboost_{version}.pkl')
            if not os.path.exists(path):
                 path = os.path.join(MODELS_DIR, 'catboost.pkl')
        elif model_type == 'tabnet':
            model = KeibaTabNet()
            # TabNet special case: zip vs pkl
            path_zip = os.path.join(MODELS_DIR, f'tabnet_{version}.zip')
            if os.path.exists(path_zip):
                path = path_zip.replace('.zip', '.pkl')
            else:
                path = os.path.join(MODELS_DIR, 'tabnet.pkl')

        if not os.path.exists(path) and not (model_type == 'tabnet' and os.path.exists(path.replace('.pkl', '.zip'))):
            return None, f"Model file not found: {path} (Type: {model_type}, Ver: {version})"

        try:
            model.load_model(path)
            return model, f"Loaded: {os.path.basename(path)}"
        except Exception as e:
            return None, f"Error loading model: {e}"

    @st.cache_resource
    def load_preprocessor_resources():
        preprocessor = InferencePreprocessor()
        return preprocessor

    # Data Loader for historical data (Heavy)
    @st.cache_resource
    def get_historical_data():
        data_path = os.path.join(PROJECT_ROOT, 'data/processed/preprocessed_data.parquet')
        if os.path.exists(data_path):
            st.info("Loading historical data to memory (One-time operation)...")
            return pd.read_parquet(data_path)
        return None

    # UI Inputs
    # Row 1: Race Selection
    st.subheader("Ë®≠ÂÆö (Settings)")
    col_in1, col_in2, col_in3 = st.columns(3)
    with col_in1:
        selected_date = st.date_input(
            "ÈñãÂÇ¨Êó•",
            value=pd.Timestamp.now(),
            min_value=pd.Timestamp('2020-01-01'),
            max_value=pd.Timestamp.now() + pd.Timedelta(days=30)
        )
        target_date = selected_date.strftime('%Y%m%d')
    with col_in2:
        venue_map = {
            '01': 'Êú≠Âπå', '02': 'ÂáΩÈ§®', '03': 'Á¶èÂ≥∂', '04': 'Êñ∞ÊΩü', '05': 'Êù±‰∫¨', 
            '06': '‰∏≠Â±±', '07': '‰∏≠‰∫¨', '08': '‰∫¨ÈÉΩ', '09': 'Èò™Á•û', '10': 'Â∞èÂÄâ'
        }
        venue_code = st.selectbox("ÈñãÂÇ¨Â†¥ÊâÄ", options=list(venue_map.keys()), format_func=lambda x: f"{x}: {venue_map[x]}")
    with col_in3:
        race_no = st.number_input("„É¨„Éº„ÇπÁï™Âè∑", min_value=1, max_value=12, value=11)

    # Row 2: Model Selection
    col_mod1, col_mod2 = st.columns(2)
    with col_mod1:
        model_type = st.selectbox("‰ΩøÁî®„É¢„Éá„É´", ['ensemble', 'lgbm', 'catboost', 'tabnet'], index=0)
    
    # Dynamic version loading
    avail_versions = get_model_versions(model_type)
    if not avail_versions:
        avail_versions = ['v1'] # Fallback
        
    with col_mod2:
        # Default to last one
        default_idx = len(avail_versions) - 1
        model_version = st.selectbox("„É¢„Éá„É´„Éê„Éº„Ç∏„Éß„É≥", avail_versions, index=default_idx)

    st.info(f"Target: {target_date} / {venue_map.get(venue_code)} / {race_no}R | Model: {model_type} ({model_version})")

    if st.button("‰∫àÊ∏¨ÂÆüË°å (Predict)"):
        with st.spinner('„É¢„Éá„É´„Å®„Éá„Éº„Çø„ÇíÊ∫ñÂÇô‰∏≠...'):
            model, msg = load_model_resources(model_type, model_version)
            if model:
                st.success(msg)
            else:
                st.error(msg)
            
            hist_df = get_historical_data() # Cached load
            
            if model is None:
                pass # Already showed error
            elif hist_df is None:
                st.error("ÈÅéÂéª„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì (data/processed/preprocessed_data.parquet)")
            else:
                # 1. „Éá„Éº„Çø„É≠„Éº„Éâ
                loader = InferenceDataLoader()
                try:
                    # Load all races for the date then filter
                    new_df = loader.load(target_date=target_date)
                except Exception as e:
                    new_df = pd.DataFrame()
                    st.error(f"„Éá„Éº„Çø„É≠„Éº„Éâ„Ç®„É©„Éº: {e}")

                # Filter by Venue and Race No
                if not new_df.empty:
                    # Ensure types match for filtering
                    # new_df['venue'] is code string '05', venue_code is '05'
                    # new_df['race_number'] is int, race_no is int
                    new_df = new_df[
                        (new_df['venue'] == venue_code) & 
                        (new_df['race_number'] == race_no)
                    ]

                if new_df.empty:
                    st.warning(f"„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü (Date: {target_date}, Venue: {venue_code}, Race: {race_no})„ÄÇPC-KEIBA„Åß„Éá„Éº„ÇøÁôªÈå≤Ê∏à„Åø„ÅãÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
                else:
                    st.success(f"„Éá„Éº„Çø„É≠„Éº„ÉâÊàêÂäü: {len(new_df)} È†≠")
                    
                    # 2. ÂâçÂá¶ÁêÜ
                    # „Éí„Çπ„Éà„É™„Ç´„É´„Éá„Éº„Çø„ÅÆ„É≠„Éº„Éâ„ÇíÈ´òÈÄüÂåñ„Åô„Çã„Åü„ÇÅ„Å´„Ç≠„É£„ÉÉ„Ç∑„É•Âà©Áî®
                    preprocessor = InferencePreprocessor()
                    
                    try:
                        # ‰øÆÊ≠£: „Ç≠„É£„ÉÉ„Ç∑„É•„Åó„Åühistory_df„ÇíÊ∏°„Åô
                        X, ids = preprocessor.preprocess(new_df, history_df=hist_df)
                        
                        if X.empty:
                            st.error("ÂâçÂá¶ÁêÜÂæå„ÅÆÁâπÂæ¥Èáè„ÅåÁîüÊàê„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
                        else:
                            # „É¨„Éº„ÇπÊÉÖÂ†±„Ç´„Éº„Éâ„ÅÆË°®Á§∫
                            race_info = new_df.iloc[0]
                            
                            # „Éû„ÉÉ„Éî„É≥„Ç∞ËæûÊõ∏
                            surface_map = {'10': 'Ëäù', '11': 'Ëäù„ÉªÁõ¥Á∑ö', '20': '„ÉÄ„Éº„Éà', '21': '„ÉÄ„Éº„Éà„ÉªÁõ¥Á∑ö', '30': 'ÈöúÂÆ≥„ÉªËäù', '31': 'ÈöúÂÆ≥„ÉªËäùÁõ¥Á∑ö'}
                            state_map = {'1': 'ËâØ', '2': 'Á®çÈáç', '3': 'Èáç', '4': '‰∏çËâØ'}
                            weather_map = {'1': 'Êô¥', '2': 'Êõá', '3': 'Èõ®', '4': 'Â∞èÈõ®', '5': 'Â∞èÈõ™', '6': 'Èõ™'}
                            
                            st.markdown("---")
                            st.subheader(f"üìã „É¨„Éº„ÇπÊÉÖÂ†±")
                            
                            info_col1, info_col2, info_col3 = st.columns(3)
                            with info_col1:
                                st.metric("„É¨„Éº„ÇπÂêç", race_info.get('title', 'N/A'))
                                st.metric("Ë∑ùÈõ¢", f"{race_info.get('distance', 'N/A')}m")
                            with info_col2:
                                surf = surface_map.get(str(race_info.get('surface', '')), 'N/A')
                                st.metric("È¶¨Â†¥", surf)
                                state = state_map.get(str(race_info.get('state', '')), 'N/A')
                                st.metric("È¶¨Â†¥Áä∂ÊÖã", state)
                            with info_col3:
                                weather = weather_map.get(str(race_info.get('weather', '')), 'N/A')
                                st.metric("Â§©ÂÄô", weather)
                                st.metric("Âá∫Ëµ∞È†≠Êï∞", f"{len(new_df)}È†≠")
                            
                            st.markdown("---")
                            
                            # 3. ‰∫àÊ∏¨
                            # ÁâπÂæ¥Èáè„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ („É¢„Éá„É´„ÅåË¶ÅÊ±Ç„Åô„Çã„ÇÇ„ÅÆ„Å†„Åë„Å´Áµû„Çã)
                            if hasattr(model, 'model') and hasattr(model.model, 'feature_name'): # LightGBM
                                required_features = model.model.feature_name()
                                missing = set(required_features) - set(X.columns)
                                if not missing:
                                    X = X[required_features]
                            elif hasattr(model, 'model') and hasattr(model.model, 'feature_names_'): # CatBoost
                                required_features = model.model.feature_names_
                                missing = set(required_features) - set(X.columns)
                                if not missing:
                                    X = X[required_features]
                            
                            preds = model.predict(X)
                            
                            # ÁµêÊûúÊï¥ÂΩ¢
                            results = ids.copy()
                            results['score'] = preds
                            results['prob'] = results.groupby('race_id')['score'].transform(lambda x: softmax(x))
                            
                            # ÊúüÂæÖÂÄ§Ë®àÁÆó
                            results['expected_value'] = results['prob'] * results['odds']
                            results['recommended'] = results['expected_value'] > 1.0
                            
                            # Ë°®Á§∫Áî®„Ç´„É©„É†
                            results['pred_rank'] = results.groupby('race_id')['score'].rank(ascending=False, method='min')
                            
                            # Ë©≥Á¥∞ÊÉÖÂ†±„ÇíË°®Á§∫
                            display_cols = ['pred_rank', 'horse_number', 'horse_name', 'score', 'prob', 'odds', 'popularity', 'expected_value']
                            display_df = results.sort_values('pred_rank')[display_cols]
                            
                            # „Ç´„É©„É†ÂêçÊó•Êú¨Ë™ûÂåñ
                            rename_map = {
                                'pred_rank': '‰∫àÊÉ≥È†Ü‰Ωç',
                                'horse_number': 'È¶¨Áï™',
                                'horse_name': 'È¶¨Âêç',
                                'score': '‰∫àÊ∏¨„Çπ„Ç≥„Ç¢',
                                'prob': 'AIÂãùÁéá',
                                'odds': 'ÂçòÂãù„Ç™„ÉÉ„Ç∫',
                                'popularity': '‰∫∫Ê∞ó',
                                'expected_value': 'ÊúüÂæÖÂÄ§'
                            }
                            display_df = display_df.rename(columns=rename_map)
                            
                            # Ëâ≤‰ªò„Åë„Å®„Éè„Ç§„É©„Ç§„Éà
                            st.subheader(f"üéØ ‰∫àÊ∏¨ÁµêÊûú: {venue_map.get(venue_code, venue_code)} {race_no}R")
                            
                            # „Åä„Åô„Åô„ÇÅÈ¶¨„ÅÆÊï∞„ÇíË°®Á§∫
                            rec_count = results['recommended'].sum()
                            if rec_count > 0:
                                st.info(f"üí° ÊúüÂæÖÂÄ§„Åå1.0„ÇíË∂Ö„Åà„Çã„Äå„Åä„Åô„Åô„ÇÅÈ¶¨„Äç„Åå {rec_count} È†≠„ÅÑ„Åæ„ÅôÔºàÈªÑËâ≤„ÉªËµ§Ëâ≤„Åß„Éè„Ç§„É©„Ç§„ÉàÔºâ")
                            
                            def highlight_rows(s):
                                rank = s['‰∫àÊÉ≥È†Ü‰Ωç']
                                exp_val = s.get('ÊúüÂæÖÂÄ§', 0)
                                is_rec = exp_val > 1.0
                                
                                # „Çà„ÇäÊ∑°„ÅÑËâ≤„ÅßË¶ã„ÇÑ„Åô„Åè
                                if is_rec and rank == 1:
                                    return ['background-color: #ffb3ba; color: black'] * len(s)  # „É©„Ç§„Éà„Éî„É≥„ÇØ
                                elif is_rec:
                                    return ['background-color: #ffffba; color: black'] * len(s)  # „É©„Ç§„Éà„Ç§„Ç®„É≠„Éº
                                elif rank == 1:
                                    return ['background-color: #ffe6e6; color: black'] * len(s)  # Ê•µËñÑ„Éî„É≥„ÇØ
                                elif rank <= 3:
                                    return ['background-color: #f5f5f5; color: black'] * len(s)  # ËñÑ„Ç∞„É¨„Éº
                                else:
                                    return [''] * len(s)

                            # style.apply „ÅØ axis=1 „ÅßË°å„Åî„Å®„Å´ÈÅ©Áî®
                            st.dataframe(
                                display_df.style.apply(highlight_rows, axis=1).format({
                                    '‰∫àÊ∏¨„Çπ„Ç≥„Ç¢': '{:.4f}', 
                                    'AIÂãùÁéá': '{:.2%}',
                                    'ÊúüÂæÖÂÄ§': '{:.2f}'
                                })
                            )

                    except Exception as e:
                        st.error(f"‰∫àÊ∏¨ÂÆüË°å‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}")
