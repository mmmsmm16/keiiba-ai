import lightgbm as lgb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import pickle
import logging
import json

logger = logging.getLogger(__name__)

class KeibaLGBM:
    """
    LightGBM (LambdaRank) ã‚’ä½¿ç”¨ã—ãŸç«¶é¦¬äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self, params=None):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (LambdaRankç”¨)
        self.params = {
            'objective': 'lambdarank',
            'metric': 'ndcg',
            'ndcg_eval_at': [1, 3, 5],
            'boosting_type': 'gbdt',
            'learning_rate': 0.05,
            'num_leaves': 31,
            'min_data_in_leaf': 20,
            'random_state': 42,
            'verbose': -1
        }
        
        # å¼•æ•°æŒ‡å®šãŒã‚ã‚Œã°ä¸Šæ›¸ã
        if params:
            self.params.update(params)

        self.model = None

    def train(self, train_set: dict, valid_set: dict):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã¾ã™ã€‚

        Args:
            train_set (dict): {'X': DataFrame, 'y': Series, 'group': Array}
            valid_set (dict): {'X': DataFrame, 'y': Series, 'group': Array}
        """
        logger.info("LightGBMã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
        w_train = train_set.get('w')
        w_valid = valid_set.get('w')
        
        # å›å¸°ãƒ¢ãƒ¼ãƒ‰ (v13) ã‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ (v12) ã‹ã‚’åˆ¤å®š
        is_ranking = self.params.get('objective') == 'lambdarank'
        
        if is_ranking:
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰: groupãŒå¿…è¦
            lgb_train = lgb.Dataset(train_set['X'], label=train_set['y'], group=train_set['group'], weight=w_train)
            lgb_valid = lgb.Dataset(valid_set['X'], label=valid_set['y'], group=valid_set['group'], reference=lgb_train, weight=w_valid)
            logger.info("ğŸ“Š LambdaRank ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã—ã¾ã™")
        else:
            # å›å¸°ãƒ¢ãƒ¼ãƒ‰: groupã¯ä¸è¦
            lgb_train = lgb.Dataset(train_set['X'], label=train_set['y'], weight=w_train)
            lgb_valid = lgb.Dataset(valid_set['X'], label=valid_set['y'], reference=lgb_train, weight=w_valid)
            logger.info(f"ğŸ“Š {self.params.get('objective', 'regression')} ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã—ã¾ã™")

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        callbacks = [
            lgb.early_stopping(stopping_rounds=50),
            lgb.log_evaluation(period=50)
        ]

        self.model = lgb.train(
            self.params,
            lgb_train,
            num_boost_round=1000,
            valid_sets=[lgb_train, lgb_valid],
            callbacks=callbacks
        )
        logger.info("å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        æ¨è«–ã‚’è¡Œã„ã¾ã™ã€‚
        """
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        
        # ç‰¹å¾´é‡ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (å­¦ç¿’æ™‚ã«ä½¿ç”¨ã—ãŸç‰¹å¾´é‡ã®ã¿ã«çµã‚‹)
        if hasattr(self.model, 'feature_name'):
            required_features = self.model.feature_name()
            # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¶³ã‚Šã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            missing = set(required_features) - set(X.columns)
            if missing:
                # æ¬ æãŒã‚ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹ã‹ã€NaNã§åŸ‹ã‚ã‚‹ã‹ã ãŒã€é€šå¸¸ã¯ã‚¨ãƒ©ãƒ¼ãŒæœ›ã¾ã—ã„
                # ã—ã‹ã—Dashboardç­‰ã§ä¸€éƒ¨æ¬ æè¨±å®¹ã™ã‚‹ãªã‚‰è­¦å‘Šãªã©ã€‚ã“ã“ã§ã¯å³å¯†ã«ãƒã‚§ãƒƒã‚¯ã€‚
                pass # LightGBMæœ¬ä½“ãŒã‚¨ãƒ©ãƒ¼ã‚’å‡ºã™ã®ã§ãã®ã¾ã¾ã«ã™ã‚‹ã€ã‚ã‚‹ã„ã¯ç‹¬è‡ªã‚¨ãƒ©ãƒ¼å‡ºã™
            
            # ä½™åˆ†ãªã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆã¯å‰Šé™¤ã—ã¦ã€é †åºã‚’åˆã‚ã›ã‚‹
            if len(X.columns) != len(required_features) or list(X.columns) != required_features:
                 # logger.debug("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚’å­¦ç¿’æ™‚ã®å½¢å¼ã«åˆã‚ã›ã¾ã™ã€‚")
                 X = X[required_features]

        return self.model.predict(X, num_iteration=self.model.best_iteration)

    def save_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’pickleå½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'wb') as f:
            pickle.dump(self.model, f)
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {path}")

    def load_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"""
        with open(path, 'rb') as f:
            self.model = pickle.load(f)
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {path}")

    def plot_importance(self, output_path: str):
        """ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ä¿å­˜ã—ã¾ã™ã€‚"""
        if not self.model:
            return
        plt.figure(figsize=(10, 6))
        lgb.plot_importance(self.model, max_num_features=20, figsize=(10, 6))
        plt.tight_layout()
        plt.savefig(output_path)
        plt.close()
        logger.info(f"ç‰¹å¾´é‡é‡è¦åº¦ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
