import argparse
import sys
import os
import yaml
import pandas as pd
import numpy as np
import pickle
import logging

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„Å∏„ÅÆ„Éë„ÇπËøΩÂä†
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

from src.preprocessing.feature_pipeline import FeaturePipeline
from src.preprocessing.loader import JraVanDataLoader
from src.preprocessing.cleansing import DataCleanser

# „É≠„Ç∞Ë®≠ÂÆö
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def load_config(config_path: str):
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def main():
    # v05_sire„Çí„Éá„Éï„Ç©„É´„Éà„Å®„Åó„Å§„Å§„ÄÅÂºïÊï∞„Åß„ÇÇÊåáÂÆöÂèØËÉΩ„Å´
    default_config = "config/experiments/exp_v05_sire.yaml"
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", default=default_config, help="Path to config yaml")
    args = parser.parse_args()

    config = load_config(args.config)
    exp_name = config.get('experiment_name')
    feature_blocks = config.get('features', [])
    
    logger.info(f"üöÄ Simulation 2025 for {exp_name}")
    logger.info(f"Features: {feature_blocks}")

    # 1. Load Data (2025 Full Year)
    loader = JraVanDataLoader()
    start_date = '2025-01-01'
    end_date = '2025-12-31'
    
    logger.info(f"Loading data ({start_date} ~ {end_date})...")
    # history_start_date„Çí2025-01-01„Å´„Åô„Çã„Å®„ÄÅÈÅéÂéªËµ∞ÈõÜË®àÁî®„ÅÆ„Éá„Éº„Çø„ÅåË∂≥„Çä„Å™„Åè„Å™„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã
    # FeaturePipeline„ÅØÂÜÖÈÉ®„ÅßÈÅéÂéª„Éá„Éº„Çø„ÇíÂøÖË¶Å„Å®„Åô„ÇãÂ†¥Âêà„Åå„ÅÇ„Çã„Åå„ÄÅ
    # loader„ÅØÊåáÂÆöÊúüÈñì„ÅÆ„Éá„Éº„Çø„Åó„ÅãËøî„Åï„Å™„ÅÑ„ÄÇ
    # „Åó„Åã„Åó FeaturePipeline „ÅÆÂÆüË£Ö„ÇíË¶ã„Çã„Å®„ÄÅÊ∏°„Åï„Çå„Åü DF ÂÜÖ„Åß„ÅÆ„ÅøÈõÜË®à„ÇíË°å„Å£„Å¶„ÅÑ„Çã (shift, rolling)„ÄÇ
    # „Å§„Åæ„Çä„ÄÅ2025Âπ¥„ÅÆ„Éá„Éº„Çø„Å†„Åë„ÇíÊ∏°„Åô„Å®„ÄÅ1Êúà„ÅÆ„É¨„Éº„Çπ„ÅÆ„ÄåÈÅéÂéª5Ëµ∞„Äç„ÅØÊ¨†Êêç„Åô„Çã„ÄÇ
    # Ê≠£Á¢∫„Å™„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„ÅÆ„Åü„ÇÅ„Å´„ÅØ„ÄÅ2024Âπ¥‰ª•Ââç„ÅÆ„Éá„Éº„Çø„ÇÇÂê´„ÇÅ„Å¶„É≠„Éº„Éâ„Åó„ÄÅ
    # ÁâπÂæ¥ÈáèÁîüÊàêÂæå„Å´ 2025Âπ¥ÂàÜ„ÅÆ„Åø„Çí„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ
    
    # ‰ΩôË£ï„ÇíÊåÅ„Å£„Å¶1Âπ¥Ââç„Åã„Çâ„É≠„Éº„Éâ
    load_start = '2024-01-01'
    logger.info(f"  Fetching data from {load_start} (for history context)...")
    raw_df = loader.load(history_start_date=load_start, end_date=end_date, jra_only=True)
    
    cleanser = DataCleanser()
    clean_df = cleanser.cleanse(raw_df)
    
    # 2. Generate Features
    pipeline = FeaturePipeline(cache_dir="data/features")
    # force=False„Åß„Ç≠„É£„ÉÉ„Ç∑„É•„Åå„ÅÇ„Çå„Å∞‰Ωø„ÅÜ
    df_features = pipeline.load_features(clean_df, feature_blocks)
    
    # 3. Merge Metadata (Odds, Result, Date) for Simulation
    # df_features „ÅØ feature columns + keys „ÅÆ„Åø
    meta_cols = ['race_id', 'horse_number', 'date', 'rank', 'odds', 'horse_name']
    # unique key„Åß„Éû„Éº„Ç∏
    df_sim = pd.merge(
        df_features, 
        clean_df[meta_cols], 
        on=['race_id', 'horse_number'], 
        how='inner'
    )
    
    # 4. Filter for 2025
    df_sim['date'] = pd.to_datetime(df_sim['date'])
    df_2025 = df_sim[(df_sim['date'] >= start_date) & (df_sim['date'] <= end_date)].copy()
    
    logger.info(f"Simulation Targets: {len(df_2025)} rows (2025)")
    
    # 5. Load Model & Predict
    model_path = f"models/experiments/{exp_name}/model.pkl"
    if not os.path.exists(model_path):
        logger.error(f"Model not found: {model_path}")
        return

    with open(model_path, 'rb') as f:
        model = pickle.load(f)
        
    # ÁâπÂæ¥Èáè„Ç´„É©„É†„ÅÆ„ÅøÊäΩÂá∫ (df_features„ÅÆ„Ç´„É©„É† - keys)
    # df_features„ÅÆË¶ÅÁ¥†È†ÜÂ∫è„ÅåÂ§â„Çè„Å£„Å¶„ÅÑ„Çã„Å®Âç±Èô∫„Å™„ÅÆ„Åß„ÄÅ
    # load_features„ÅÆÊàª„ÇäÂÄ§„ÅÆ„Ç´„É©„É†„Çí‰Ωø„ÅÜ„ÅÆ„ÅåÂÆâÂÖ®Ôºàmeta_cols„ÅØÈô§Â§ñÔºâ
    # feature_cols = [c for c in df_features.columns if c not in ['race_id', 'horse_number', 'horse_id']]
    # „Åó„Åã„Åó df_2025 „Å´„ÅØ meta_cols „ÅåÊ∑∑„Åñ„Å£„Å¶„ÅÑ„Çã„ÄÇ
    # model.predict „Å´Ê∏°„Åô X „ÅØ„ÄÅÂ≠¶ÁøíÊôÇ„Å®Âêå„Åò„Ç´„É©„É†ÊßãÊàê„Åß„Å™„Åë„Çå„Å∞„Å™„Çâ„Å™„ÅÑ„ÄÇ
    
    # Feature Alignment
    model_features = model.feature_name()
    logger.info(f"Model expects {len(model_features)} features: {model_features}")
    
    # ÂûãÂ§âÊèõ (age„ÅØÊï∞ÂÄ§„ÅÆ„ÅØ„Åö„Å†„Ååobject„Å´„Å™„ÇãÂ†¥Âêà„Åå„ÅÇ„Çã„Åü„ÇÅÂº∑Âà∂Â§âÊèõ)
    if 'age' in df_2025.columns:
        df_2025['age'] = pd.to_numeric(df_2025['age'], errors='coerce')

    # „Ç´„É©„É†Â≠òÂú®„ÉÅ„Çß„ÉÉ„ÇØ„Å®‰∏¶„ÅπÊõø„Åà
    X = pd.DataFrame(index=df_2025.index)
    for feat in model_features:
        if feat in df_2025.columns:
            X[feat] = df_2025[feat]
        else:
            logger.warning(f"Feature {feat} is missing in data. Filling with 0.")
            X[feat] = 0
            
    # ‰ΩôÂàÜ„Å™„Ç´„É©„É†„ÅØËá™ÂãïÁöÑ„Å´Èô§Â§ñ„Åï„Çå„Çã (X„ÅØ‰ΩúÊàêÊôÇÁ©∫„Å™„ÅÆ„Åß)
    
    logger.info("Predicting...")
    # Binary„É¢„Éá„É´„Å™„ÅÆ„ÅßÁ¢∫Áéá„ÅåÂá∫Âäõ„Åï„Çå„Çã„ÅØ„Åö (predict vs predict_proba check)
    # LightGBM sklearn API„Å™„Çâ predict_proba„Å†„Åå„ÄÅNative API (train) „Å™„Çâ predict „ÅåÁ¢∫Áéá
    # run_experiment.py „Åß„ÅØ lgb.train „Çí‰ΩøÁî® -> predict returns probability
    probs = model.predict(X)
    df_2025['pred_prob'] = probs
    
    # 6. Simulation (Flat Betting, EV >= 1.0)
    # EV = prob * odds
    # odds „ÅØ ÂçòÂãù„Ç™„ÉÉ„Ç∫
    df_2025['ev'] = df_2025['pred_prob'] * df_2025['odds']
    
    # Ë≥ºÂÖ•Êù°‰ª∂
    # odds > 1.0 (ÂÖÉËøî„ÅóÈô§Â§ñ), EV >= 1.0 (ÊúüÂæÖÂÄ§1‰ª•‰∏ä)
    # ‚Äª ÂÆüÈÅãÁî®„Åß„ÅØ‰∫∫Ê∞óËñÑ„Åô„Åé„Çã„Å®Ëçí„Çå„Çã„ÅÆ„ÅßË∂≥Âàá„Çä„Åô„Çã„Åì„Å®„ÇÇ„ÅÇ„Çã„Åå„ÄÅ‰ªäÂõû„ÅØÁ¥îÁ≤ã„Å™ÊÄßËÉΩ„ÇíË¶ã„Çã
    bets = df_2025[
        (df_2025['ev'] >= 1.0) & 
        (df_2025['odds'].notna()) & 
        (df_2025['rank'] > 0) # ÁµêÊûú„Åå„ÅÇ„Çã„ÇÇ„ÅÆ
    ].copy()
    
    logger.info(f"Bet Candidates: {len(bets)} / {len(df_2025)}")
    
    # ÊúàÊ¨°ÈõÜË®à
    bets['month'] = bets['date'].dt.strftime('%Y-%m')
    bets['cost'] = 100
    bets['return'] = np.where(bets['rank'] == 1, bets['odds'] * 100, 0)
    
    monthly_stats = bets.groupby('month').agg({
        'race_id': 'count', # Bet Count
        'cost': 'sum',
        'return': 'sum'
    }).rename(columns={'race_id': 'bets'})
    
    monthly_stats['net'] = monthly_stats['return'] - monthly_stats['cost']
    monthly_stats['roi'] = (monthly_stats['return'] / monthly_stats['cost']) * 100
    
    # Total Stats
    total_bets = monthly_stats['bets'].sum()
    total_cost = monthly_stats['cost'].sum()
    total_return = monthly_stats['return'].sum()
    total_net = total_return - total_cost
    total_roi = (total_return / total_cost) * 100 if total_cost > 0 else 0
    
    # ÁµêÊûúË°®Á§∫
    print("\nXXX Simulation Result 2025 (Flat Betting, EV>=1.0) XXX")
    print(f"Model: {exp_name}")
    print(monthly_stats[['bets', 'return', 'net', 'roi']])
    print("-" * 50)
    print(f"Yearly Total:")
    print(f"  Bets: {total_bets}")
    print(f"  Cost: {total_cost:,.0f} JPY")
    print(f"  Return: {total_return:,.0f} JPY")
    print(f"  Net: {total_net:,.0f} JPY")
    print(f"  ROI: {total_roi:.2f}%")
    print("-" * 50)
    
    # „É≠„Ç∞‰øùÂ≠ò
    out_path = f"reports/simulation_{exp_name}_2025.csv"
    bets.to_csv(out_path, index=False)
    logger.info(f"Detailed simulation log saved to {out_path}")

if __name__ == "__main__":
    main()
