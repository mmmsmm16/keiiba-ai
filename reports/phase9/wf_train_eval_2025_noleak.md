# Phase 9: No-Leak 再学習と評価レポート (2025年)

## 1. エグゼクティブサマリー
Phase 9の目的は、2025年の「No-Leak」ベースラインで確認された低いROI (71.6%) の原因を診断し、真にリークのない堅牢な学習パイプラインを確立することでした。

- **ベースライン診断**: 当初のモデルが「人気順 (Popularity)」のリークに大きく依存しており、スコアがインフレしていたことを確認しまし。これを除去すると、ROIは約71%（ランダム相当）まで低下しました。
- **リークの発見**: 当初、再学習で非現実的なROI (260-300%) が算出されましたが、これは前処理済みデータ内の `raw_time`（走破時計）、`last_3f`（上がり3F）、`pass_order`（通過順）、`relative_popularity`（相対人気） にリークが含まれていたためと判明しました。
- **解決策**: 再学習において、**厳格な許可リスト (Strict Allowlist)** 方式を採用しました（過去の戦績、埋め込み表現、IDのみを使用）。
- **最終結果**: ウォークフォワード検証 (2025年1月〜3月) の結果は以下の通りです。
    - **LogLoss**: **0.2020** (市場ベースライン 0.2091 を上回る精度)
    - **ROI (EV > 1.0)**: **90.47%** (保守的、対象43レース)
    - **結論**: モデルは市場確率に対して有意な予測能力（Alpha）を持っていますが、現在の閾値ではベット数が少なく保守的すぎるため、キャリブレーションや閾値調整が必要です。

## 2. 診断: 市場 vs モデル
2025年の予測セット (T-10m No-Leak) を分析しました。
- **市場精度 (T-10m)**: LogLoss 0.2091, AUC 0.829
- **モデル精度 (Residual)**: LogLoss 0.2020
    - モデルは市場確率に対し、統計的に有意な改善を示しています。
- **ROI vs EV閾値**:
    - 厳格なモデルは非常に保守的です。EV > 1.0 の条件では、3ヶ月でわずか43件のベットしか行わず、回収率は90%でした。
    - 高い予測精度を活かすには、閾値を下げる（例: EV > 0.8）などの調整が必要と考えられます。

## 3. 再学習の方法論
「学習と推論の乖離 (Skew)」とリークを排除するため、**ウォークフォワード再学習パイプライン**を構築しました。
- **学習データ**: 2013年〜2024年 (月次で追加)
- **特徴量**: **厳格な許可リスト** (~110特徴量)
    - *採用*: `lag1_*` (前走成績), `mean_*` (平均成績), `*_emb_*` (埋め込み), `horse_id`, `jockey_id`, `trainer_id`, `distance`, `weight`
    - *除外*: `odds`, `popularity`, `rank` (着順), `time` (タイム), `3f`, `pass_order`, `p_market`
- **目的変数**: `rank=1` (1着)
- **ベースマージン (Base Margin)**:
    - 学習時: `logit(1/FinalOdds)` (最終オッズからの残差を学習)
    - 推論時: `logit(1/T-10mOdds)` (学習した残差をT-10mオッズに適用)

## 4. リーク事案の分析
開発中、`preprocessed_data.parquet` に明示的に削除したカラム以外にも、微妙なリークが含まれていることが発見されました。
- `raw_time` / `last_3f`: 結果に直結するタイム情報
- `pass_{1-4}`: 通過順（結果と強い相関）
- `relative_popularity_rank`: 最終人気から派生

*対応*: 「禁止リスト(Blocklist)」方式は不完全であるため、「許可リスト(Allowlist)」方式に切り替え、リークを完全に遮断しました。

## 5. 次のステップ (Phase 10)
1.  **通年再学習**: 厳格な許可リストを用いたパイプラインで、2025年通年 (1月〜12月) の予測を実行します。
2.  **キャリブレーション**: モデルの予測確率 (`pred_prob`) を実際の勝率に合わせるよう補正（Calibrate）し、有効なベット数を増やします。
3.  **感度分析**: 再学習モデルに対してBeta値やEV閾値のスイープを行い、利益が出るゾーン（おそらく EV > 0.8〜0.9）を特定します。

## 成果物
- **スクリプト**: `src/experiments/phase9_wf_retrain.py`
- **レポート**: `reports/phase9/wf_train_eval_2025_noleak.md`
- **予測データ**: `data/predictions/v13_wf_2025_retrained_residual.parquet`
