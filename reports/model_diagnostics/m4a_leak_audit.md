
# M4-A Leakage Audit Report

## 1. 概要
M4-A実験において `Recall@5 = 0.9635` という異常に高い数値が記録されたため、リークの可能性を懸念して緊急監査を実施した。

## 2. 監査結果

### 2-1. コード監査 (Static/Dynamic)
- **特徴量ロジック (`temporal_stats.py`)**:
    - `compute_rolling_stats`: `closed='left'` (当日除外) および厳密な時系列ソートを確認。
    - `compute_relative_stats`: `shift(1)` により過去の統計のみを使用していることを確認。
    - 監査スクリプト (`audit_m4a_leak.py`) によるダミーデータ検証で、当日リーク（自分自身の値の混入）が無いことを実証済み。
- **データパイプライン (`feature_pipeline.py`)**:
    - 中間変数 `is_top3` 等が最終的な特徴量として出力されていないことを確認。

### 2-2. データ分割監査
- `DatasetSplitter` は `year` カラムに基づき厳密に Train (<2024) / Valid (2024) を分割している。
- `run_experiment.py` ログ上のデータ件数 (Valid: 71k) は多いが、NARデータを含んでいるための仕様動作であり、自己相関リークではない。

### 2-3. 特徴量重要度 (Feature Importance)
- `check_m4a_importance.py` によるモデル解析結果:
    - 1位: `mean_rank_5` (過去5走平均着順) - 26%
    - 2位: `lag1_rank` (前走着順) - 16%
    - ...
    - `relative_z` (M4-A特徴量) は Top 10 に入るが、シェアは 2.5% 程度。
- **結論**: `rank` (当日着順) や `odds` (確定オッズ) などの明白なリーク変数は上位に含まれておらず、モデルは過去の実績を正しく学習している。

## 3. 異常値の真因 (Root Cause)
**設定ミスによる「Top2モデル」の学習**

- **発見**: `config/experiments/exp_m4_a_top3.yaml` の設定を確認したところ、意図した `target_top3` ではなく、コピー元の `target_top2` (2着以内) が指定されていた。
- **メカニズム**:
    - モデルは「2着以内に入る強い馬」を識別するように学習された（信号がTop3より明確）。
    - 評価指標 `Recall@5` (target='top3') は、「予測Top5の中に、3着以内の馬が1頭でも入れば正解」とする甘い指標である。
    - Top2に入るような強い馬を高精度で予測できるモデルは、必然的に「Top3に入る馬（少なくとも1頭）」をほぼ確実に捉えることができる。
    - 結果として、**Recall@5 = 0.9635** という極めて高いスコアが記録された。これはリークではなく、**Top2モデルの優秀さと評価指標の性質によるもの**である。

## 4. 対応
1.  **Config修正**: `exp_m4_a_top3.yaml` のターゲットを `target_top3` に修正する。
2.  **再実験**: 正しいターゲットでモデルを学習し、指標が常識的な範囲（0.75-0.80程度と予想）に落ち着くか確認する。
3.  **知見**: 「Top2モデルの予測値をTop3選定に流用する」ことが、Top3モデルを直接学習するよりも高Recallを生む可能性がある（今後のアンサンブル戦略に活用）。

## 結論
**No Code/Data Leakage Found.**
数値の異常は Config 設定ミスと、異なるタスク（Top2予測）による副作用である。
