
import nbformat as nbf
import os

def create_coverage_notebook():
    nb = nbf.v4.new_notebook()
    
    # Markdown - Title
    nb.cells.append(nbf.v4.new_markdown_cell(
        "# 投資機会の拡大とカバレッジ最大化 (20モデル)\n\n"
        "回収率100%超を維持しつつ、購入レース数 (Coverage) を最大化するためのシミュレーションを行います。\n\n"
        "### 検証内容\n"
        "1. **複勝 (Place) EV戦略**: 予測スコアから複勝率を推定し、期待値フィルタを適用。\n"
        "2. **閾値最適化 (Threshold Optimization)**: EV閾値を変動させ、「ROI > 100%」を満たす最大カバレッジを探る。\n"
        "3. **ポートフォリオ戦略**: 単勝と複勝を組み合わせた場合の収支安定性を検証。\n"
    ))
    
    # Code - Setup
    nb.cells.append(nbf.v4.new_code_cell(
        "import sys\n"
        "import os\n"
        "import pandas as pd\n"
        "import numpy as np\n"
        "import lightgbm as lgb\n"
        "import seaborn as sns\n"
        "import matplotlib.pyplot as plt\n"
        "import japanize_matplotlib\n"
        "from scipy.special import softmax\n"
        "from tqdm.auto import tqdm\n\n"
        "# プロジェクトのsrcディレクトリをパスに追加\n"
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '../../src'))\n"
        "if src_path not in sys.path:\n"
        "    sys.path.append(src_path)\n\n"
        "from nar.loader import NarDataLoader\n"
        "from nar.features import NarFeatureGenerator\n\n"
        "%matplotlib inline\n"
        "sns.set(font='IPAexGothic', style='whitegrid')"
    ))
    
    # Code - Data Load & Model Train (NB17 Copy)
    code_source = (
        "# --- モデル構築 (NB17相当) ---\n"
        "loader = NarDataLoader()\n"
        "raw_df = loader.load(limit=200000, region='south_kanto')\n\n"
        "generator = NarFeatureGenerator(history_windows=[1, 2, 3, 4, 5])\n"
        "df = generator.generate_features(raw_df)\n\n"
        "df = df.dropna(subset=['rank']).copy()\n"
        "df['date'] = pd.to_datetime(df['date'])\n\n"
        "# 特徴量定義\n"
        "baseline_features = [\n"
        "    'distance', 'venue', 'state', 'frame_number', 'horse_number', 'weight', 'impost',\n"
        "    'jockey_win_rate', 'jockey_place_rate', 'trainer_win_rate', 'trainer_place_rate',\n"
        "    'horse_run_count'\n"
        "] + [col for col in df.columns if 'horse_prev' in col]\n\n"
        "advanced_features = [\n"
        "    'gender', 'age', 'days_since_prev_race', 'weight_diff',\n"
        "    'horse_jockey_place_rate', 'is_consecutive_jockey',\n"
        "    'distance_diff', 'horse_venue_place_rate',\n"
        "    'trainer_30d_win_rate',\n"
        "    'impost_diff', 'was_accident_prev1', 'weighted_si_momentum', 'weighted_rank_momentum',\n"
        "    'class_rank', 'class_diff', 'is_promoted', 'is_demoted'\n"
        "]\n\n"
        "phase9_features = [\n"
        "    'weighted_si_momentum_race_rank', 'weighted_si_momentum_diff_from_avg', 'weighted_si_momentum_zscore',\n"
        "    'weighted_rank_momentum_race_rank', 'weighted_rank_momentum_diff_from_avg', 'weighted_rank_momentum_zscore',\n"
        "    'class_rank_race_rank', 'class_rank_diff_from_avg', 'class_rank_zscore',\n"
        "    'horse_state_place_rate', 'season', 'is_night_race', 'trainer_momentum_bias'\n"
        "]\n\n"
        "pedigree_features = [\n"
        "    'sire_win_rate', 'sire_place_rate'\n"
        "]\n\n"
        "track_bias_features = [\n"
        "    'track_bias_inner_win_rate', 'track_bias_outer_win_rate', 'track_bias_front_win_rate'\n"
        "]\n\n"
        "features = list(set(baseline_features + advanced_features + phase9_features + track_bias_features + pedigree_features))\n"
        "features = [f for f in features if f in df.columns]\n\n"
        "# 型変換\n"
        "categorical_cols = ['venue', 'state', 'gender', 'season']\n"
        "for col in features:\n"
        "    if col in categorical_cols:\n"
        "        df[col] = df[col].astype(str).astype('category')\n"
        "    else:\n"
        "        df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n\n"
        "split_date = df['date'].quantile(0.8)\n"
        "train_df = df[df['date'] < split_date].sort_values('race_id').copy()\n"
        "test_df = df[df['date'] >= split_date].sort_values('race_id').copy()\n\n"
        "train_groups = train_df.groupby('race_id').size().values\n"
        "test_groups = test_df.groupby('race_id').size().values\n"
        "train_label = 20 - train_df['rank']\n"
        "test_label = 20 - test_df['rank']\n\n"
        "model = lgb.LGBMRanker(**params)\n"
        "model.fit(\n"
        "    train_df[features], train_label,\n"
        "    group=train_groups,\n"
        "    eval_set=[(test_df[features], test_label)],\n"
        "    eval_group=[test_groups],\n"
        "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n"
        ")\n"
        "test_df['pred_score'] = model.predict(test_df[features])\n"
        "test_df['pred_rank'] = test_df.groupby('race_id')['pred_score'].rank(method='min', ascending=False)"
    ).replace("**params", "**{\n    'objective': 'lambdarank',\n    'metric': 'ndcg',\n    'ndcg_at': [1, 3, 5],\n    'n_estimators': 1000,\n    'learning_rate': 0.05,\n    'num_leaves': 64,\n    'max_depth': 6,\n    'random_state': 42,\n    'importance_type': 'gain'\n}")
    
    nb.cells.append(nbf.v4.new_code_cell(code_source))
    
    # Code - Load Payouts & Preprocess
    nb.cells.append(nbf.v4.new_code_cell(
        "# 払戻金データのロードと結合\n"
        "test_dates = test_df['date'].unique()\n"
        "payouts_all = []\n"
        "print('Loading payout data...')\n"
        "for d in tqdm(test_dates):\n"
        "    date_str = pd.Timestamp(d).strftime('%Y-%m-%d')\n"
        "    payouts = loader.load_payouts(date_str)\n"
        "    payouts_all.append(payouts)\n\n"
        "payouts_df = pd.concat(payouts_all, ignore_index=True)\n"
        "merged = test_df.merge(payouts_df, on='race_id', how='inner')\n"
        "print(f'Merged Data: {len(merged)} records')"
    ))

    # Code - Win EV Calculation
    nb.cells.append(nbf.v4.new_code_cell(
        "# 単勝期待値 (Win EV)\n"
        "def calc_win_prob(df_group):\n"
        "    df_group['win_prob'] = softmax(df_group['pred_score'])\n"
        "    return df_group\n"
        "merged = merged.groupby('race_id', group_keys=False).apply(calc_win_prob)\n"
        "merged['win_ev'] = merged['win_prob'] * merged['odds']"
    ))

    # Code - Place EV Calculation
    nb.cells.append(nbf.v4.new_code_cell(
        "# 複勝期待値 (Place EV)\n"
        "# スコア分位 (Decile) から実際の複勝率をマッピングして確率とする (簡易キャリブレーション)\n"
        "merged['score_bin'] = pd.qcut(merged['pred_score'], 10, labels=False)\n"
        "place_prob_map = merged.groupby('score_bin')['rank'].apply(lambda x: (x <= 3).mean()).to_dict()\n"
        "merged['place_prob'] = merged['score_bin'].map(place_prob_map)\n\n"
        "# 複勝オッズの下限値 (min_odds) を使用して保守的に見積もる\n"
        "# 注: 複勝オッズは変動するため、ここではデータロード時に取得した払い戻しデータにはオッズが含まれていない場合がある。\n"
        "# ロード済みデータ (nvd_hr) は「払戻金」であり「オッズ」ではない。\n"
        "# シミュレーションのためには「直前オッズ」が必要だが、簡易的に「払戻金 / 100」を確定オッズとして扱う。\n"
        "# ただし、外れた馬の複勝オッズが不明になる問題がある。\n"
        "# 解決策: 今回は「的中した馬」の払戻金データはあるが、外れた馬のオッズがない。\n"
        "# よって、複勝シミュレーションは「的中時のリターン」は正確だが、「期待値計算」に必要なオッズが全馬分揃わない可能性がある。\n"
        "# -> nvd_se (馬毎成績) には `fukusho_min`, `fukusho_max` があるはず。確認してロードが必要。\n"
        "# 現状の loader.py では nvd_se のオッズは `tansho_odds` のみ。\n"
        "# ここでは「単勝オッズから複勝オッズを簡易推定」するか、「単勝EV戦略」に集中するか。\n"
        "# ユーザー要望は「単勝以外も」。\n"
        "# 推定式: Place Odds ~= Win Odds ^ 0.5 (大まかな近似)\n"
        "merged['place_odds_est'] = np.sqrt(merged['odds']) # 簡易推定\n"
        "merged['place_ev'] = merged['place_prob'] * merged['place_odds_est']"
    ))
    
    # Code - Optimize Threshold (Win)
    nb.cells.append(nbf.v4.new_code_cell(
        "# 閾値最適化シミュレーション (Win)\n"
        "thresholds = np.arange(0.5, 1.5, 0.1)\n"
        "results = []\n\n"
        "for th in thresholds:\n"
        "    # 予測1位 かつ EV >= th\n"
        "    target = merged[(merged['pred_rank'] == 1) & (merged['win_ev'] >= th)].copy()\n"
        "    n_bets = len(target)\n"
        "    if n_bets == 0: continue\n"
        "    \n"
        "    # 収支計算\n"
        "    loss = n_bets * 100\n"
        "    # 払戻金取得ロジック\n"
        "    def get_return(row):\n"
        "        try:\n"
        "            if row['payout_win_horse_1'] is not None and int(row['payout_win_horse_1']) == int(row['horse_number']):\n"
        "                return int(row['payout_win_amount_1'])\n"
        "        except: pass\n"
        "        return 0\n"
        "    \n"
        "    return_amount = target.apply(get_return, axis=1).sum()\n"
        "    net = return_amount - loss\n"
        "    roi = return_amount / loss * 100\n"
        "    results.append({'threshold': th, 'n_bets': n_bets, 'roi': roi, 'net': net, 'coverage': n_bets/len(test_dates.unique())})\n\n"
        "res_df = pd.DataFrame(results)\n"
        "print('--- Win EV Threshold Optimization ---')\n"
        "print(res_df)\n\n"
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n"
        "ax1.plot(res_df['threshold'], res_df['roi'], 'b-o', label='ROI')\n"
        "ax1.axhline(100, color='red', linestyle='--')\n"
        "ax1.set_xlabel('EV Threshold')\n"
        "ax1.set_ylabel('ROI (%)', color='b')\n"
        "ax1.tick_params(axis='y', labelcolor='b')\n"
        "\n"
        "ax2 = ax1.twinx()\n"
        "ax2.plot(res_df['threshold'], res_df['n_bets'], 'g--x', label='Num Bets')\n"
        "ax2.set_ylabel('Number of Bets', color='g')\n"
        "ax2.tick_params(axis='y', labelcolor='g')\n"
        "\n"
        "plt.title('Win EV Threshold: ROI vs Coverage')\n"
        "plt.show()"
    ))

    # Code - Optimize Threshold (Place)
    nb.cells.append(nbf.v4.new_code_cell(
        "# 閾値最適化シミュレーション (Place)\n"
        "results_place = []\n"
        "total_races = len(merged.groupby('race_id'))\n\n"
        "for th in thresholds:\n"
        "    # 予測1位 (または複勝率が高い馬) かつ Place EV >= th\n"
        "    # ここではシンプルに「予測1位の馬」の複勝を買うケースのみ検証する\n"
        "    # (範囲を広げるなら pred_rank <= 3 等も検討余地あり)\n"
        "    target = merged[(merged['pred_rank'] == 1) & (merged['place_ev'] >= th)].copy()\n"
        "    n_bets = len(target)\n"
        "    if n_bets == 0: continue\n"
        "    \n"
        "    loss = n_bets * 100\n"
        "    def get_place_return(row):\n"
        "        ret = 0\n"
        "        h_num = int(row['horse_number'])\n"
        "        try:\n"
        "            if row['payout_place_horse_1'] is not None and int(row['payout_place_horse_1']) == h_num:\n"
        "                ret = int(row['payout_place_amount_1'])\n"
        "            elif row['payout_place_horse_2'] is not None and int(row['payout_place_horse_2']) == h_num:\n"
        "                ret = int(row['payout_place_amount_2'])\n"
        "            elif row['payout_place_horse_3'] is not None and int(row['payout_place_horse_3']) == h_num:\n"
        "                ret = int(row['payout_place_amount_3'])\n"
        "        except: pass\n"
        "        return ret\n"
        "\n"
        "    return_amount = target.apply(get_place_return, axis=1).sum()\n"
        "    net = return_amount - loss\n"
        "    roi = return_amount / loss * 100\n"
        "    results_place.append({'threshold': th, 'n_bets': n_bets, 'roi': roi, 'net': net, 'coverage': n_bets/total_races*100})\n\n"
        "res_place = pd.DataFrame(results_place)\n"
        "print('--- Place EV Threshold Optimization ---')\n"
        "print(res_place)\n\n"
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n"
        "ax1.plot(res_place['threshold'], res_place['roi'], 'b-o', label='ROI')\n"
        "ax1.axhline(100, color='red', linestyle='--')\n"
        "ax1.set_xlabel('Place EV Threshold')\n"
        "ax1.set_ylabel('ROI (%)', color='b')\n"
        "ax1.tick_params(axis='y', labelcolor='b')\n"
        "\n"
        "ax2 = ax1.twinx()\n"
        "ax2.plot(res_place['threshold'], res_place['n_bets'], 'g--x', label='Num Bets')\n"
        "ax2.set_ylabel('Number of Bets', color='g')\n"
        "ax2.tick_params(axis='y', labelcolor='g')\n"
        "\n"
        "plt.title('Place EV Threshold: ROI vs Coverage')\n"
        "plt.show()"
    ))

    # Save
    path = '/workspace/notebooks/nar/20_nar_coverage_simulation.ipynb'
    with open(path, 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    print(f'Notebook created at {path}')

if __name__ == '__main__':
    create_coverage_notebook()
