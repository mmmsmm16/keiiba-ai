name: m3_win_decay_piecewise
base_config: config/base_config.yaml

experiment:
  description: "Phase M3-Next: Win Model with Piecewise Time-Decay"
  output_dir: "models/experiments/m3_win_decay_piecewise"

model_params:
  # Win model typically needs higher regularization as positive samples are sparse
  learning_rate: 0.05
  num_leaves: 31
  max_depth: 7
  min_data_in_leaf: 50
  bagging_fraction: 0.8
  feature_fraction: 0.8
  lambda_l1: 0.5
  lambda_l2: 0.5
  objective: "binary"
  metric: ["auc", "binary_logloss"]

dataset:
  target_col: "target_win" # Win target (1st place)
  train_start_date: "2015-01-01"
  train_end_date: "2023-12-31" # Validation year is typically excluded from train
  valid_year: 2024
  drop_market_data: true
  features:
    - "base_attributes"
    - "history_stats"
    - "jockey_stats"
    - "pace_stats"
    - "bloodline_stats"
    - "training_stats"
    - "burden_stats"
    - "changes_stats"
    - "aptitude_stats"
    - "speed_index_stats"
    - "pace_pressure_stats"
    - "relative_stats"
    - "jockey_trainer_stats"

features:
  - "base_attributes"
  - "history_stats"
  - "jockey_stats"
  - "pace_stats"
  - "bloodline_stats"
  - "training_stats"
  - "burden_stats"
  - "changes_stats"
  - "aptitude_stats"
  - "speed_index_stats"
  - "pace_pressure_stats"
  - "relative_stats"
  - "jockey_trainer_stats"

sample_weight:
  enabled: true
  strategy: "piecewise"
  normalize: true
  year_weights:
    2024: 1.0 # High emphasis on latest trend
    2023: 0.7
    2022: 0.5
    default: 0.3 # Older data decayed significantly

post_processing:
  calibration:
    enabled: true
    method: "isotonic"
    n_bins: 10
